{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from textblob import TextBlob\n",
    "from tweepy import API\n",
    "from tweepy import Cursor\n",
    "from tweepy import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = ''\n",
    "ACCESS_TOKEN = ''\n",
    "ACCESS_TOKEN_SECRET = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient():\n",
    "    def __init__(self, twitter_user=None):\n",
    "        self.auth = TwitterAuthenticator().authenticate_twitter_app()\n",
    "        self.twitter_client = API(self.auth)\n",
    "    \n",
    "        self.twitter_user = twitter_user\n",
    "        \n",
    "    def get_twitter_client_api(self):\n",
    "        return self.twitter_client\n",
    "        \n",
    "    def get_user_timeline_tweets(self, num_tweets):\n",
    "        tweets = []\n",
    "        for tweet in Cursor(self.twitter_client.user_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            tweets.append(tweet)\n",
    "        return tweets\n",
    "    \n",
    "    def get_friend_list(self, num_friends):\n",
    "        friend_list = []\n",
    "        for friend in Cursor(self.twitter_client.friends).items(num_friends):\n",
    "            friend_list.append(friend)\n",
    "            return friend_list\n",
    "        \n",
    "    def get_home_timeline_tweets(self, num_tweets):\n",
    "        home_timeline_tweets = []\n",
    "        for tweet in Cursor(self.twitter_client.home_timeline).items(num_tweets):\n",
    "            home_timeline_tweets.append(tweet)\n",
    "        return home_timeline_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for Authenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter authenticator\n",
    "class TwitterAuthenticator():\n",
    "    def authenticate_twitter_app(self):\n",
    "        auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "        auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "        return auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for Reg[ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetAnalyzer():\n",
    "    def remove_emoji(self, tweet):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   u\"\\U0001f926-\\U0001f937\"\n",
    "                                   u\"\\U00010000-\\U0010ffff\"\n",
    "                                   u\"\\u2640-\\u2642\"\n",
    "                                   u\"\\u2600-\\u2B55\"\n",
    "                                   u\"\\u200d\"\n",
    "                                   u\"\\u23cf\"\n",
    "                                   u\"\\u23e9\"\n",
    "                                   u\"\\u231a\"\n",
    "                                   u\"\\ufe0f\"  # dingbats\n",
    "                                   u\"\\u3030\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r\" \", tweet)\n",
    "    \n",
    "    def cleanerText(self, tweet):\n",
    "        tweet = re.sub(r'[0-9]', ' ',tweet) #remove number\n",
    "        tweet = re.sub(r'@[A-Za-z0-9]+', ' ', tweet) #removed @mentions\n",
    "        tweet = re.sub(r'#([a-zA-Z0-9_]+)', ' ', tweet) #removing # symbol\n",
    "        tweet = re.sub(r'RT[\\s]+', ' ', tweet) #removing \n",
    "        tweet = re.sub(r'(http|https):\\/\\/([\\w\\s\\d\\.]+)(\\/?)(.*)',' ',tweet)#remove hyper link\n",
    "        tweet = re.sub(r'(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', tweet)\n",
    "        tweet = tweet.lower()\n",
    "        return tweet\n",
    "    \n",
    "    def cleaner(self, tweet):\n",
    "        tweet = re.sub(r'[0-9]', ' ',tweet) #remove number\n",
    "        tweet = re.sub(r'@[A-Za-z0-9]+', ' ', tweet) #removed @mentions\n",
    "        tweet = re.sub(r'#([a-zA-Z0-9_]+)', ' ', tweet) #removing # symbol\n",
    "        tweet = re.sub(r'RT[\\s]+', ' ', tweet) #removing \n",
    "        tweet = re.sub(r'(http|https):\\/\\/([\\w\\s\\d\\.]+)(\\/?)(.*)',' ',tweet)#remove hyper link\n",
    "        tweet = re.sub(r'(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', tweet)\n",
    "        tweet = tweet.lower()\n",
    "        return tweet.split()\n",
    "    \n",
    "    def clean_tweet(self, tweet):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    \n",
    "    def analyze_sentiment(self, tweet):\n",
    "        analysis = TextBlob(self.cleanerText(tweet))\n",
    "        \n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 1\n",
    "        elif analysis.sentiment.polarity ==0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    #Store data into DataFrame\n",
    "    #for analyze and categorizing content from tweets\n",
    "    def tweets_to_data_frame(self, tweets):\n",
    "        df = pd.DataFrame(data=[tweet.full_text for tweet in tweets])\n",
    "        df['tweets'] = np.array([tweet.full_text for tweet in tweets])\n",
    "        df['tweet_id'] = np.array([tweet.id for tweet in tweets])\n",
    "        df['username'] = np.array([tweet.user.screen_name for tweet in tweets])\n",
    "        df['len'] = np.array([len(tweet.full_text) for tweet in tweets])\n",
    "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "        df['source'] = np.array([tweet.source for tweet in tweets])\n",
    "        df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "        df['location'] = np.array([tweet.user.location for tweet in tweets])\n",
    "        df['is_Quotes']= np.array([tweet.is_quote_status for tweet in tweets])\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    twitter_client = TwitterClient()\n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "    api = twitter_client.get_twitter_client_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweet from Jawa Barat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File berhasil dibuat\n"
     ]
    }
   ],
   "source": [
    "    #jawa barat\n",
    "    searchTerms= \"#sedih OR #marah OR #depresi OR menyedihkan OR kesepian OR sengsara OR sakit OR aku OR diriku sendiri OR selalu OR selengkapnya OR tidak pernah\"\n",
    "    tweets = [tweet for tweet in tweepy.Cursor(api.search, q=searchTerms +\"-filter:retweets exclude:replies\", lang = 'id', geocode=\"-6.814630,107.131828,200km\", \n",
    "                                               tweet_mode=\"extended\").items(3000)]\n",
    "    \n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.remove_emoji(tweet) for tweet in df['tweets']])\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.cleanerText(tweet) for tweet in df['tweets']])\n",
    "    df['cleanTweet'] = np.array([tweet_analyzer.cleaner(tweet) for tweet in df['tweets']])\n",
    "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
    "    \n",
    "    df = pd.DataFrame({'tweet_id': df['tweet_id'],'length of word': df['len'],'location': df['location'],'username': df['username'], \n",
    "                                           'tweet': df['tweets'], 'deEmoji': df['deEmoji'], 'cleanTweet': df['cleanTweet'], 'sentiment': df['sentiment'], 'date': df['date']})\n",
    "    filename = 'jabar_excel.xlsx'\n",
    "    filename2 = 'jabar_Csv.csv'\n",
    "    df.to_excel(filename)\n",
    "    df.to_csv(filename2)\n",
    "    print('File berhasil dibuat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweet from Jawa Tengah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File berhasil dibuat\n"
     ]
    }
   ],
   "source": [
    "    #jawa tengah\n",
    "    searchTerms= \"#sedih OR #marah OR #depresi OR menyedihkan OR kesepian OR sengsara OR sakit OR aku OR diriku sendiri OR selalu OR selengkapnya OR tidak pernah\"\n",
    "    tweets = [tweet for tweet in tweepy.Cursor(api.search, q=searchTerms +\"-filter:retweets exclude:replies\", lang = 'id', geocode=\"-7.517260,110.593430,150km\", \n",
    "                                               tweet_mode=\"extended\").items(1500)]\n",
    "    \n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.remove_emoji(tweet) for tweet in df['tweets']])\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.cleanerText(tweet) for tweet in df['tweets']])\n",
    "    df['cleanTweet'] = np.array([tweet_analyzer.cleaner(tweet) for tweet in df['tweets']])\n",
    "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
    "    \n",
    "    df = pd.DataFrame({'tweet_id': df['tweet_id'],'length of word': df['len'],'location': df['location'],'username': df['username'], \n",
    "                                           'tweet': df['tweets'], 'deEmoji': df['deEmoji'], 'cleanTweet': df['cleanTweet'], 'sentiment': df['sentiment'], 'date': df['date']})\n",
    "    filename = 'jateng_excel.xlsx'\n",
    "    filename2 = 'jateng_Csv.csv'\n",
    "    df.to_excel(filename)\n",
    "    df.to_csv(filename2)\n",
    "    print('File berhasil dibuat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweet from Jawa Timur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File berhasil dibuat\n"
     ]
    }
   ],
   "source": [
    "    #jawa timur\n",
    "    searchTerms= \"#sedih OR #marah OR #depresi OR menyedihkan OR kesepian OR sengsara OR sakit OR aku OR diriku sendiri OR selalu OR selengkapnya OR tidak pernah\"\n",
    "    tweets = [tweet for tweet in tweepy.Cursor(api.search, q=searchTerms +\"-filter:retweets exclude:replies\", lang = 'id', geocode=\"-7.781430,112.902344,150km\", \n",
    "                                               tweet_mode=\"extended\").items(1500)]\n",
    "    \n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.remove_emoji(tweet) for tweet in df['tweets']])\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.cleanerText(tweet) for tweet in df['tweets']])\n",
    "    df['cleanTweet'] = np.array([tweet_analyzer.cleaner(tweet) for tweet in df['tweets']])\n",
    "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
    "    \n",
    "    df = pd.DataFrame({'tweet_id': df['tweet_id'],'length of word': df['len'],'location': df['location'],'username': df['username'], \n",
    "                                           'tweet': df['tweets'], 'deEmoji': df['deEmoji'], 'cleanTweet': df['cleanTweet'], 'sentiment': df['sentiment'], 'date': df['date']})\n",
    "    filename = 'jatim_excel.xlsx'\n",
    "    filename2 = 'jatim_Csv.csv'\n",
    "    df.to_excel(filename)\n",
    "    df.to_csv(filename2)\n",
    "    print('File berhasil dibuat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweet from Sumatra Utara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File berhasil dibuat\n"
     ]
    }
   ],
   "source": [
    "    #sumatra utara\n",
    "    searchTerms= \"#sedih OR #marah OR #depresi OR menyedihkan OR kesepian OR sengsara OR sakit OR aku OR diriku sendiri OR selalu OR selengkapnya OR tidak pernah\"\n",
    "    tweets = [tweet for tweet in tweepy.Cursor(api.search, q=searchTerms +\"-filter:retweets exclude:replies\", lang = 'id', geocode=\"2.8901607,99.1788304,140km\", \n",
    "                                               tweet_mode=\"extended\").items(1500)]\n",
    "\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.remove_emoji(tweet) for tweet in df['tweets']])\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.cleanerText(tweet) for tweet in df['tweets']])\n",
    "    df['cleanTweet'] = np.array([tweet_analyzer.cleaner(tweet) for tweet in df['tweets']])\n",
    "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
    "    \n",
    "    df = pd.DataFrame({'tweet_id': df['tweet_id'],'length of word': df['len'],'location': df['location'],'username': df['username'], \n",
    "                                           'tweet': df['tweets'], 'deEmoji': df['deEmoji'], 'cleanTweet': df['cleanTweet'], 'sentiment': df['sentiment'], 'date': df['date']})\n",
    "    filename = 'sumut_excel.xlsx'\n",
    "    filename2 = 'sumut_Csv.csv'\n",
    "    df.to_excel(filename)\n",
    "    df.to_csv(filename2)\n",
    "    print('File berhasil dibuat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweet from Sumatra Selatan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File berhasil dibuat\n"
     ]
    }
   ],
   "source": [
    "    #sumatra selatan\n",
    "    searchTerms= \"#sedih OR #marah OR #depresi OR menyedihkan OR kesepian OR sengsara OR sakit OR aku OR diriku sendiri OR selalu OR selengkapnya OR tidak pernah\"\n",
    "    tweets = [tweet for tweet in tweepy.Cursor(api.search, q=searchTerms +\"-filter:retweets exclude:replies\", lang = 'id', geocode=\"-3.13174,103.588986,200km\", \n",
    "                                               tweet_mode=\"extended\").items(1500)]\n",
    "\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.remove_emoji(tweet) for tweet in df['tweets']])\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.cleanerText(tweet) for tweet in df['tweets']])\n",
    "    df['cleanTweet'] = np.array([tweet_analyzer.cleaner(tweet) for tweet in df['tweets']])\n",
    "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
    "    \n",
    "    df = pd.DataFrame({'tweet_id': df['tweet_id'],'length of word': df['len'],'location': df['location'],'username': df['username'], \n",
    "                                           'tweet': df['tweets'], 'deEmoji': df['deEmoji'], 'cleanTweet': df['cleanTweet'], 'sentiment': df['sentiment'], 'date': df['date']})\n",
    "    filename = 'sumsel_excel.xlsx'\n",
    "    filename2 = 'sumsel_Csv.csv'\n",
    "    df.to_excel(filename)\n",
    "    df.to_csv(filename2)\n",
    "    print('File berhasil dibuat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweet from Bali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File berhasil dibuat\n"
     ]
    }
   ],
   "source": [
    "    #Bali\n",
    "    searchTerms= \"#sedih OR #marah OR #depresi OR menyedihkan OR kesepian OR sengsara OR sakit OR aku OR diriku sendiri OR selalu OR selengkapnya OR tidak pernah\"\n",
    "    tweets = [tweet for tweet in tweepy.Cursor(api.search, q=searchTerms +\"-filter:retweets exclude:replies\", lang = 'id', geocode=\"-8.340539,115.091949,73km\", \n",
    "                                               tweet_mode=\"extended\").items(1500)]\n",
    "\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.remove_emoji(tweet) for tweet in df['tweets']])\n",
    "    df['deEmoji'] = np.array([tweet_analyzer.cleanerText(tweet) for tweet in df['tweets']])\n",
    "    df['cleanTweet'] = np.array([tweet_analyzer.cleaner(tweet) for tweet in df['tweets']])\n",
    "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
    "    \n",
    "    df = pd.DataFrame({'tweet_id': df['tweet_id'],'length of word': df['len'],'location': df['location'],'username': df['username'], \n",
    "                                           'tweet': df['tweets'], 'deEmoji': df['deEmoji'], 'cleanTweet': df['cleanTweet'], 'sentiment': df['sentiment'], 'date': df['date']})\n",
    "    filename = 'bali_excel.xlsx'\n",
    "    filename2 = 'bali_Csv.csv'\n",
    "    df.to_excel(filename)\n",
    "    df.to_csv(filename2)\n",
    "    print('File berhasil dibuat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing - Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\GL553VD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re  \n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('stopwords')  \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"Data10k_Csv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig_dims = (20, 10)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "sns.countplot(x='sentiment', data=tweets)\n",
    "sns.countplot(x='location', data=tweets)\n",
    "sns.countplot(x='location', hue=\"sentiment\", data=tweets, palette='Set3', ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()\n",
    "tweets.shape\n",
    "X = tweets.iloc[:, 7].values  \n",
    "y = tweets.iloc[:, 8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of raw Tweet :  ['mungkin kau selalu menduga diriku tidak pernah memahamimu bahkan kau selalu curiga ada yang lain dan kuduakan cintamu'\n",
      " 'aku tidak kehilangan seorang teman pun aku hanya baru sadar kalau tidak pernah memilikinya'\n",
      " 'manusia tidak akan pernah selesai dengan seluruh pertengkaran dendam kebencian bully dan caci maki kalau hanya saling menyombongkan kebenaran masing-masing menuhankan kebenaran masing-masing cobalah merendah oh barangkali aku yang salah mereka yang benar'\n",
      " 'aku menyesal bahwa selama ini aku tidak pernah berani melangkah untuk memulai hal yang baru tapi aku sangat bersyukur hingga saat ini aku selalu dibersamai dengan orang yang selalu mendorong untuk berani maju melangkah'\n",
      " 'jangan pernah merasa sendiri lihatlah aku yang tidak pernah pergi dan selalu berusaha untuk ada disaat kamu sedih meskipun terkadang aku menjauh saat kamu senang']\n",
      "\n",
      "\n",
      "List of raw Target :  ['Terindikasi Depresi' 'Terindikasi Depresi' 'Tidak Terindikasi'\n",
      " 'Tidak Terindikasi' 'Terindikasi Depresi']\n"
     ]
    }
   ],
   "source": [
    "print('List of raw Tweet : ', X[0:5])\n",
    "print('\\n')\n",
    "print('List of raw Target : ', y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing - Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    tweet = ' '.join(tweet.split())\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_da = [case_folding(tweet) for tweet in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Case Folded Tweet :  ['mungkin kau selalu menduga diriku tidak pernah memahamimu bahkan kau selalu curiga ada yang lain dan kuduakan cintamu', 'aku tidak kehilangan seorang teman pun aku hanya baru sadar kalau tidak pernah memilikinya', 'manusia tidak akan pernah selesai dengan seluruh pertengkaran dendam kebencian bully dan caci maki kalau hanya saling menyombongkan kebenaran masingmasing menuhankan kebenaran masingmasing cobalah merendah oh barangkali aku yang salah mereka yang benar', 'aku menyesal bahwa selama ini aku tidak pernah berani melangkah untuk memulai hal yang baru tapi aku sangat bersyukur hingga saat ini aku selalu dibersamai dengan orang yang selalu mendorong untuk berani maju melangkah', 'jangan pernah merasa sendiri lihatlah aku yang tidak pernah pergi dan selalu berusaha untuk ada disaat kamu sedih meskipun terkadang aku menjauh saat kamu senang']\n"
     ]
    }
   ],
   "source": [
    "print('List of Case Folded Tweet : ', X_da[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing - Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_da = [word_tokenize(tweet) for tweet in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Tokenize Tweet :  [['mungkin', 'kau', 'selalu', 'menduga', 'diriku', 'tidak', 'pernah', 'memahamimu', 'bahkan', 'kau', 'selalu', 'curiga', 'ada', 'yang', 'lain', 'dan', 'kuduakan', 'cintamu'], ['aku', 'tidak', 'kehilangan', 'seorang', 'teman', 'pun', 'aku', 'hanya', 'baru', 'sadar', 'kalau', 'tidak', 'pernah', 'memilikinya'], ['manusia', 'tidak', 'akan', 'pernah', 'selesai', 'dengan', 'seluruh', 'pertengkaran', 'dendam', 'kebencian', 'bully', 'dan', 'caci', 'maki', 'kalau', 'hanya', 'saling', 'menyombongkan', 'kebenaran', 'masing-masing', 'menuhankan', 'kebenaran', 'masing-masing', 'cobalah', 'merendah', 'oh', 'barangkali', 'aku', 'yang', 'salah', 'mereka', 'yang', 'benar'], ['aku', 'menyesal', 'bahwa', 'selama', 'ini', 'aku', 'tidak', 'pernah', 'berani', 'melangkah', 'untuk', 'memulai', 'hal', 'yang', 'baru', 'tapi', 'aku', 'sangat', 'bersyukur', 'hingga', 'saat', 'ini', 'aku', 'selalu', 'dibersamai', 'dengan', 'orang', 'yang', 'selalu', 'mendorong', 'untuk', 'berani', 'maju', 'melangkah'], ['jangan', 'pernah', 'merasa', 'sendiri', 'lihatlah', 'aku', 'yang', 'tidak', 'pernah', 'pergi', 'dan', 'selalu', 'berusaha', 'untuk', 'ada', 'disaat', 'kamu', 'sedih', 'meskipun', 'terkadang', 'aku', 'menjauh', 'saat', 'kamu', 'senang']]\n"
     ]
    }
   ],
   "source": [
    "print('List of Tokenize Tweet : ', X_da[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing - Stopwords - NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "listStopword = set(stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(tweet):\n",
    "    result = []\n",
    "    for token in tweet:\n",
    "        if token not in listStopword:\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = []\n",
    "for tweet in X_da:\n",
    "    X_temp.append(stopwords_removal(tweet))\n",
    "\n",
    "X_da = X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Tweet After Stopwords :  [['kau', 'menduga', 'diriku', 'memahamimu', 'kau', 'curiga', 'kuduakan', 'cintamu'], ['kehilangan', 'teman', 'sadar', 'memilikinya'], ['manusia', 'selesai', 'pertengkaran', 'dendam', 'kebencian', 'bully', 'caci', 'maki', 'menyombongkan', 'kebenaran', 'menuhankan', 'kebenaran', 'cobalah', 'merendah', 'oh', 'barangkali', 'salah'], ['menyesal', 'berani', 'melangkah', 'bersyukur', 'dibersamai', 'orang', 'mendorong', 'berani', 'maju', 'melangkah'], ['lihatlah', 'pergi', 'berusaha', 'disaat', 'sedih', 'terkadang', 'menjauh', 'senang']]\n"
     ]
    }
   ],
   "source": [
    "print('List of Tweet After Stopwords : ', X_da[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing - Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tempo = []\n",
    "for tweet in X_da:\n",
    "    X_tempo.append(stemmer.stem(' '.join(tweet)))\n",
    "    \n",
    "X_da = X_tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Tweet after stemming :  ['kau duga diri paham kau curiga dua cinta', 'hilang teman sadar milik', 'manusia selesai tengkar dendam benci bully caci maki sombong benar tuhan benar coba rendah oh barangkali salah', 'sesal berani lang syukur sama orang dorong berani maju lang', 'lihat pergi usaha saat sedih terkadang jauh senang']\n"
     ]
    }
   ],
   "source": [
    "print('List of Tweet after stemming : ', X_tempo[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('clean.csv','w')\n",
    "for line in X_da:\n",
    "    file.write(line + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat = []\n",
    "\n",
    "file = open('clean.csv','r')\n",
    "for line in file:\n",
    "    X_dat.append(line.rstrip())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "for sentimen in range(0, len(y)):\n",
    "    senti = str(y[sentimen])\n",
    "    if(senti == 'Tidak Terindikasi'):\n",
    "        senti=0\n",
    "    else:\n",
    "        senti=1\n",
    "    target.append(senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10082  -  <class 'list'>\n",
      "10082  -  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(target), ' - ', type(target))\n",
    "print(len(X_dat), ' - ', type(X_dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dat, target, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_dat, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8065\n",
      "2017\n",
      "8065\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB, ComplementNB as CNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Multinomial Naive Bayes - Word - CV 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc = MNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = Pipeline([('vectorizer', vectorizer), ('clf', mnbc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__analyzer': ['word'],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [0, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)],\n",
    "#     'vectorizer__ngram_range': [(3,3)],\n",
    "    'vectorizer__max_features' : [10000, 15000, 20000, 25000, 30000, None]\n",
    "}\n",
    "\n",
    "result_mw = GridSearchCV(model, parameters, cv=5, scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__analyzer': ['word'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__max_features': [10000, 15000, 20000,\n",
       "                                                      25000, 30000, None],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2),\n",
       "                                                     (1, 3), (2, 3), (3, 3)]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_mw.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.903657780533168\n"
     ]
    }
   ],
   "source": [
    "print('Best Score : ', result_mw.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param :  {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Param : ', result_mw.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 0]\n",
      "\n",
      "\n",
      "[[9.99748488e-01 2.51511949e-04]\n",
      " [1.72620878e-01 8.27379122e-01]\n",
      " [2.53408101e-01 7.46591899e-01]\n",
      " ...\n",
      " [2.76456756e-01 7.23543244e-01]\n",
      " [7.05856756e-01 2.94143244e-01]\n",
      " [8.09292057e-01 1.90707943e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred = result_mw.predict(X_test)\n",
    "pred_proba = result_mw.predict_proba(X_test)\n",
    "\n",
    "print(pred)\n",
    "print('\\n')\n",
    "print(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9385225582548339\n",
      "[[1079   36]\n",
      " [  88  814]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1115\n",
      "           1       0.96      0.90      0.93       902\n",
      "\n",
      "    accuracy                           0.94      2017\n",
      "   macro avg       0.94      0.94      0.94      2017\n",
      "weighted avg       0.94      0.94      0.94      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print('accuracy: ', accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Multinomial Naive Bayes - Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc = MNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = Pipeline([('vectorizer', vectorizer), ('clf', mnbc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__analyzer': ['char'],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [0, 5, 10],\n",
    "    'vectorizer__ngram_range': [(2,3), (3,3), (3,4), (3,5), (4,5), (5,5)],\n",
    "#     'vectorizer__ngram_range': [(5,5)],\n",
    "    'vectorizer__max_features' : [10000, 15000, 20000, 25000, 30000, None]\n",
    "}\n",
    "\n",
    "result_mc = GridSearchCV(model, parameters, cv=5, scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__analyzer': ['char'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__max_features': [10000, 15000, 20000,\n",
       "                                                      25000, 30000, None],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(5, 5)]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_mc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.8412895226286423\n"
     ]
    }
   ],
   "source": [
    "print('Best Score : ', result_mc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param :  {'vectorizer__analyzer': 'char', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (5, 5)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Param : ', result_mc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 0]\n",
      "\n",
      "\n",
      "[[9.99656979e-01 3.43020684e-04]\n",
      " [3.43910848e-01 6.56089152e-01]\n",
      " [3.12652911e-01 6.87347089e-01]\n",
      " ...\n",
      " [1.79034805e-01 8.20965195e-01]\n",
      " [7.15466355e-01 2.84533645e-01]\n",
      " [7.80760358e-01 2.19239642e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred = result_mc.predict(X_test)\n",
    "pred_proba = result_mc.predict_proba(X_test)\n",
    "\n",
    "print(pred)\n",
    "print('\\n')\n",
    "print(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8626673277144273\n",
      "[[1020   95]\n",
      " [ 182  720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1115\n",
      "           1       0.88      0.80      0.84       902\n",
      "\n",
      "    accuracy                           0.86      2017\n",
      "   macro avg       0.87      0.86      0.86      2017\n",
      "weighted avg       0.86      0.86      0.86      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('accuracy: ', accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Complement NB - Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc = CNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = Pipeline([('vectorizer', vectorizer), ('clf', cnbc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__analyzer': ['word'],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [0, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)],\n",
    "#     'vectorizer__ngram_range': [(3,3)],\n",
    "    'vectorizer__max_features' : [10000, 15000, 20000, 25000, 30000, None]\n",
    "}\n",
    "\n",
    "result_cnw = GridSearchCV(model, parameters, cv=5, scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', ComplementNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__analyzer': ['word'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__max_features': [10000, 15000, 20000,\n",
       "                                                      25000, 30000, None],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2),\n",
       "                                                     (1, 3), (2, 3), (3, 3)]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cnw.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.9088654680719156\n"
     ]
    }
   ],
   "source": [
    "print('Best Score : ', result_cnw.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param :  {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Param : ', result_cnw.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 0]\n",
      "\n",
      "\n",
      "[[9.99682225e-01 3.17774837e-04]\n",
      " [1.41719144e-01 8.58280856e-01]\n",
      " [2.11745431e-01 7.88254569e-01]\n",
      " ...\n",
      " [2.32183144e-01 7.67816856e-01]\n",
      " [6.55075873e-01 3.44924127e-01]\n",
      " [7.70563868e-01 2.29436132e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred = result_cnw.predict(X_test)\n",
    "pred_proba = result_cnw.predict_proba(X_test)\n",
    "\n",
    "print(pred)\n",
    "print('\\n')\n",
    "print(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9335647000495786\n",
      "[[1051   64]\n",
      " [  70  832]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1115\n",
      "           1       0.93      0.92      0.93       902\n",
      "\n",
      "    accuracy                           0.93      2017\n",
      "   macro avg       0.93      0.93      0.93      2017\n",
      "weighted avg       0.93      0.93      0.93      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('accuracy: ', accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Complement NB - Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc = CNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = Pipeline([('vectorizer', vectorizer), ('clf', cnbc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__analyzer': ['char'],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [0, 5, 10],\n",
    "    'vectorizer__ngram_range': [(2,3), (3,3), (3,4), (3,5), (4,5), (5,5)],\n",
    "#         'vectorizer__ngram_range': [(5,5)],\n",
    "    'vectorizer__max_features' : [10000, 15000, 20000, 25000, 30000, None]\n",
    "}\n",
    "\n",
    "result_cnc = GridSearchCV(model, parameters, cv=5, scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', ComplementNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__analyzer': ['char'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__max_features': [10000, 15000, 20000,\n",
       "                                                      25000, 30000, None],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(2, 3), (3, 3), (3, 4),\n",
       "                                                     (3, 5), (4, 5), (5, 5)]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cnc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.8469931804091756\n"
     ]
    }
   ],
   "source": [
    "print('Best Score : ', result_cnc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param :  {'vectorizer__analyzer': 'char', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (5, 5)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Param : ', result_cnc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 0]\n",
      "\n",
      "\n",
      "[[9.99566618e-01 4.33381849e-04]\n",
      " [2.93212371e-01 7.06787629e-01]\n",
      " [2.64703287e-01 7.35296713e-01]\n",
      " ...\n",
      " [1.47189142e-01 8.52810858e-01]\n",
      " [6.65558423e-01 3.34441577e-01]\n",
      " [7.38113039e-01 2.61886961e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred = result_cnc.predict(X_test)\n",
    "pred_proba = result_cnc.predict_proba(X_test)\n",
    "\n",
    "print(pred)\n",
    "print('\\n')\n",
    "print(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8621715418939019\n",
      "[[975 140]\n",
      " [138 764]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      1115\n",
      "           1       0.85      0.85      0.85       902\n",
      "\n",
      "    accuracy                           0.86      2017\n",
      "   macro avg       0.86      0.86      0.86      2017\n",
      "weighted avg       0.86      0.86      0.86      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('accuracy: ', accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Multinomial Naive Bayes - Word - CV 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc_cv = MNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = Pipeline([('vectorizer', vectorizer), ('clf', mnbc_cv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__analyzer': ['word'],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [0, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)],\n",
    "    'vectorizer__max_features' : [10000, 15000, 20000, 25000, 30000, None]\n",
    "}\n",
    "\n",
    "result_cvmw = GridSearchCV(model, parameters, cv=10, scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__analyzer': ['word'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__max_features': [10000, 15000, 20000,\n",
       "                                                      25000, 30000, None],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2),\n",
       "                                                     (1, 3), (2, 3), (3, 3)]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cvmw.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.9130797211742168\n"
     ]
    }
   ],
   "source": [
    "print('Best Score : ', result_cvmw.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param :  {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Param : ', result_cvmw.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9385225582548339\n",
      "[[1079   36]\n",
      " [  88  814]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      1115\n",
      "           1       0.96      0.90      0.93       902\n",
      "\n",
      "    accuracy                           0.94      2017\n",
      "   macro avg       0.94      0.94      0.94      2017\n",
      "weighted avg       0.94      0.94      0.94      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = result_cvmw.predict(X_test)\n",
    "\n",
    "print('accuracy: ', accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.17956362, 0.37369068, 0.27780712, 0.64413264, 0.54722795,\n",
      "       0.25972943, 0.12303402, 0.35378349, 0.25940597, 0.65125875,\n",
      "       0.54130673, 0.27424982, 0.11565559, 0.32156544, 0.23771651,\n",
      "       0.60653005, 0.51381032, 0.2649467 , 0.10888317, 0.43746281,\n",
      "       0.33431814, 0.67568164, 0.64433355, 0.30465419, 0.10953579,\n",
      "       0.33935406, 0.25090964, 0.82212396, 0.83874543, 0.38038735,\n",
      "       0.12310071, 0.4110729 , 0.42007973, 0.70630803, 0.62140725,\n",
      "       0.30715885, 0.12509415, 0.36954265, 0.29046192, 0.73051302,\n",
      "       0.57310543, 0.31258061, 0.12259519, 0.34783833, 0.27090402,\n",
      "       0.68054619, 0.57086589, 0.38644226, 0.12430534, 0.36106122,\n",
      "       0.26802344, 0.68494389, 0.60317235, 0.28505881, 0.12683938,\n",
      "       0.39015493, 0.29012442, 0.69842939, 0.65476005, 0.41509125,\n",
      "       0.14106975, 0.38184683, 0.27665803, 0.66907232, 0.62446787,\n",
      "       0.30517972, 0.1229866 , 0.36834092, 0.26468365, 0.6666342 ,\n",
      "       0.55780282, 0.29046726, 0.11865194, 0.40599647, 0.29559705,\n",
      "       0.69589081, 0.6150028 , 0.30569322, 0.11786528, 0.35623479,\n",
      "       0.26557679, 0.66963377, 0.56206486, 0.29189687, 0.11577215,\n",
      "       0.34609339, 0.27156944, 0.65796444, 0.59527605, 0.29987626,\n",
      "       0.12338226, 0.37992857, 0.27714694, 0.68927588, 0.58787246,\n",
      "       0.29844651, 0.1170238 , 0.31325114, 0.19238677, 0.48239815,\n",
      "       0.40709488, 0.21162221, 0.11912861, 0.25308321, 0.18755736,\n",
      "       0.43011777, 0.34983222, 0.18152578, 0.10892234, 0.37899215,\n",
      "       0.28099804, 0.67846668, 0.61083846, 0.30059171, 0.11401613,\n",
      "       0.36113484, 0.31126723, 0.6805433 , 0.60866311, 0.30551002,\n",
      "       0.12096763, 0.34540377, 0.28072021, 0.68053389, 0.55300367,\n",
      "       0.26637678, 0.11653013, 0.38722713, 0.29646847, 0.6763983 ,\n",
      "       0.60573268, 0.30623009, 0.11973562, 0.36686225, 0.28782897,\n",
      "       0.67568033, 0.5832804 , 0.29525514, 0.11828606, 0.35677152,\n",
      "       0.25389411, 0.65825541, 0.58500397, 0.29608693, 0.1153492 ,\n",
      "       0.39869642, 0.29101076, 0.69125817, 0.58915634, 0.31965144,\n",
      "       0.12074862, 0.37002585, 0.27115691, 0.6626811 , 0.593542  ,\n",
      "       0.3001796 , 0.12232661, 0.37080164, 0.28029549, 0.68961079,\n",
      "       0.55010777, 0.30231929, 0.16938601, 0.43359962, 0.29424319,\n",
      "       0.73376071, 0.60411718, 0.3095098 , 0.12843018, 0.36537118,\n",
      "       0.25984006, 0.80605438, 0.71192241, 0.35078514, 0.11814554,\n",
      "       0.36851177, 0.25950589, 0.71030605, 0.5955621 , 0.29129112,\n",
      "       0.11936865, 0.38048089, 0.28582134, 0.69224458, 0.70479867,\n",
      "       0.33401649, 0.11553414, 0.37893372, 0.27086279, 0.7349978 ,\n",
      "       0.69798512, 0.29764183, 0.11659372, 0.39188375, 0.29600453,\n",
      "       0.75498569, 0.5974395 , 0.31027236, 0.12248721, 0.40148177,\n",
      "       0.27984078, 0.70319645, 0.59993258, 0.31780746, 0.11853576,\n",
      "       0.27731633, 0.18941615, 0.47342978, 0.36174657, 0.18602531,\n",
      "       0.10550632, 0.26431243, 0.19752102, 0.44830415, 0.36515417,\n",
      "       0.18149121, 0.12037995, 0.37509639, 0.28244486, 0.68861151,\n",
      "       0.56934669, 0.2922148 , 0.11532054, 0.36704462, 0.27145875,\n",
      "       0.67154956, 0.58668485, 0.27964466, 0.11225073, 0.35625041,\n",
      "       0.27683618, 0.67428136, 0.56125302, 0.29447956, 0.12396791,\n",
      "       0.38832045, 0.28663354, 0.68640075, 0.59310358, 0.30793819,\n",
      "       0.11645403, 0.3854136 , 0.2765862 , 0.69009922, 0.70826435,\n",
      "       0.32216372, 0.14964404, 0.41070223, 0.34933553, 0.82005465,\n",
      "       0.72883101, 0.32678218, 0.13051126, 0.42937231, 0.32499063,\n",
      "       0.71078405, 0.6173059 , 0.3194314 , 0.13200407, 0.36009984,\n",
      "       0.26608868, 0.68901057, 0.59115925, 0.28808994, 0.118156  ,\n",
      "       0.35758736, 0.26431613, 0.66847899, 0.59177303, 0.28771491,\n",
      "       0.11875796, 0.39640114, 0.28566239, 0.71362116, 0.60640304,\n",
      "       0.31734524, 0.11624207, 0.36435368, 0.27513671, 0.68076921,\n",
      "       0.59986467, 0.29579916, 0.11157932, 0.34757893, 0.26330702,\n",
      "       0.66919529, 0.58309541, 0.28440554, 0.12592897, 0.38857036,\n",
      "       0.28653343, 0.71500642, 0.60462148, 0.30592768, 0.11770945,\n",
      "       0.43281138, 0.31864922, 0.72704391, 0.57483969, 0.30422764,\n",
      "       0.12619176, 0.35241618, 0.26824231, 0.69563985, 0.57137101,\n",
      "       0.29109442, 0.11541333, 0.38565722, 0.2907249 , 0.70330298,\n",
      "       0.60178566, 0.31001401, 0.11096361, 0.27284992, 0.19707475,\n",
      "       0.45600064, 0.36073761, 0.18580816, 0.10406606, 0.26101091,\n",
      "       0.18728907, 0.41973164, 0.37690284, 0.22799335]), 'std_fit_time': array([0.01981407, 0.02956467, 0.0221798 , 0.04074224, 0.03919596,\n",
      "       0.0419985 , 0.01766211, 0.03063966, 0.0220611 , 0.03549669,\n",
      "       0.02263955, 0.02969358, 0.0143998 , 0.02347823, 0.01422386,\n",
      "       0.04443232, 0.02178179, 0.03734951, 0.00984814, 0.03140439,\n",
      "       0.04656964, 0.03923186, 0.05507448, 0.05727615, 0.01594997,\n",
      "       0.0290831 , 0.0244307 , 0.10675331, 0.08690453, 0.0816875 ,\n",
      "       0.00983009, 0.03737191, 0.03493831, 0.04095513, 0.03528111,\n",
      "       0.04829202, 0.01688341, 0.04199549, 0.01788732, 0.04787993,\n",
      "       0.02007529, 0.04710586, 0.01313776, 0.03484328, 0.01607746,\n",
      "       0.05502901, 0.02512655, 0.04871335, 0.02445549, 0.03061099,\n",
      "       0.01987157, 0.03338134, 0.02190499, 0.04935608, 0.01183489,\n",
      "       0.03391301, 0.02274681, 0.05105882, 0.06532236, 0.06404857,\n",
      "       0.01909768, 0.03074052, 0.02883675, 0.04510225, 0.03023984,\n",
      "       0.03958422, 0.01745149, 0.02770597, 0.01739546, 0.05433136,\n",
      "       0.01793057, 0.03546585, 0.01639506, 0.04328674, 0.02163836,\n",
      "       0.05436495, 0.03678167, 0.03589433, 0.01923921, 0.03776417,\n",
      "       0.0222512 , 0.05186509, 0.03347802, 0.03088604, 0.01579223,\n",
      "       0.04831618, 0.01409581, 0.04576164, 0.02879244, 0.03907191,\n",
      "       0.01225323, 0.03738621, 0.0240038 , 0.06100495, 0.02824553,\n",
      "       0.03342265, 0.02110113, 0.02968836, 0.0133734 , 0.04808757,\n",
      "       0.01294669, 0.02707844, 0.00931139, 0.01693457, 0.01187775,\n",
      "       0.04680727, 0.02506509, 0.02116927, 0.01276947, 0.03607069,\n",
      "       0.01768208, 0.04014383, 0.0280318 , 0.04479449, 0.01569291,\n",
      "       0.03941607, 0.03433617, 0.0478805 , 0.03759163, 0.04678431,\n",
      "       0.01756576, 0.04105548, 0.02088493, 0.02734854, 0.05535216,\n",
      "       0.02197889, 0.01234528, 0.04312792, 0.02137365, 0.04823007,\n",
      "       0.0332924 , 0.04038016, 0.01356825, 0.03514086, 0.01807752,\n",
      "       0.06010693, 0.02467993, 0.04076627, 0.01275816, 0.03883637,\n",
      "       0.02298699, 0.05784692, 0.01929242, 0.04808175, 0.01871403,\n",
      "       0.04062146, 0.0293993 , 0.06637334, 0.01631865, 0.04122217,\n",
      "       0.01805151, 0.03163025, 0.02553232, 0.06294285, 0.02965633,\n",
      "       0.0421854 , 0.01390883, 0.04398586, 0.0336754 , 0.07054503,\n",
      "       0.03408571, 0.01772716, 0.02897319, 0.02779051, 0.02993207,\n",
      "       0.03690031, 0.01884931, 0.04325979, 0.01603773, 0.03132586,\n",
      "       0.02438664, 0.08540887, 0.05851167, 0.0673259 , 0.01292531,\n",
      "       0.03252671, 0.02005014, 0.04370786, 0.02267958, 0.03281726,\n",
      "       0.01206167, 0.04004556, 0.02121257, 0.0609604 , 0.05394116,\n",
      "       0.08065595, 0.01334306, 0.03731851, 0.01861001, 0.05311199,\n",
      "       0.03478382, 0.05826306, 0.01297671, 0.07522758, 0.03113127,\n",
      "       0.04469357, 0.02253372, 0.03918386, 0.01316569, 0.03804932,\n",
      "       0.01840743, 0.04907963, 0.03308329, 0.04387332, 0.01294384,\n",
      "       0.02502269, 0.01762983, 0.04509834, 0.02966259, 0.01098348,\n",
      "       0.0145634 , 0.01522219, 0.01341822, 0.02644747, 0.02333546,\n",
      "       0.01561985, 0.01096169, 0.03845451, 0.01665134, 0.04529236,\n",
      "       0.03283047, 0.03970525, 0.01048728, 0.03672734, 0.021152  ,\n",
      "       0.06359363, 0.03954772, 0.03017979, 0.01769197, 0.03509752,\n",
      "       0.00863277, 0.04178269, 0.02436507, 0.03770099, 0.01415841,\n",
      "       0.03474941, 0.02170412, 0.04504118, 0.02992435, 0.03664714,\n",
      "       0.01628138, 0.04127238, 0.02377606, 0.08827454, 0.0808967 ,\n",
      "       0.02396294, 0.01892785, 0.03189424, 0.02574866, 0.08609032,\n",
      "       0.04482934, 0.07493053, 0.01095586, 0.02624056, 0.01077693,\n",
      "       0.03300389, 0.01662674, 0.04976844, 0.02334235, 0.0394769 ,\n",
      "       0.02148748, 0.06617546, 0.02874123, 0.03937333, 0.01436841,\n",
      "       0.0417061 , 0.02178154, 0.04708001, 0.02297659, 0.03874718,\n",
      "       0.01708975, 0.04473327, 0.02227573, 0.05131253, 0.03220523,\n",
      "       0.04287056, 0.01432589, 0.03014605, 0.01504086, 0.07089154,\n",
      "       0.02932235, 0.0480343 , 0.01392933, 0.03647833, 0.01657915,\n",
      "       0.06667516, 0.02585603, 0.04245793, 0.01766066, 0.05106192,\n",
      "       0.02195579, 0.04537606, 0.03876042, 0.04163789, 0.01074686,\n",
      "       0.06927799, 0.02899227, 0.04481166, 0.03972367, 0.0404643 ,\n",
      "       0.01616881, 0.03719343, 0.01998017, 0.04281777, 0.02337712,\n",
      "       0.03924336, 0.01127404, 0.04542465, 0.02037033, 0.0416272 ,\n",
      "       0.03169198, 0.04737523, 0.01192088, 0.02078107, 0.01481142,\n",
      "       0.0545029 , 0.0319273 , 0.01855945, 0.00911993, 0.0116092 ,\n",
      "       0.01475113, 0.0271503 , 0.02058341, 0.06400977]), 'mean_score_time': array([0.01975908, 0.03308618, 0.02183812, 0.04897118, 0.03489695,\n",
      "       0.02017386, 0.01457577, 0.03011882, 0.02144377, 0.04487946,\n",
      "       0.03587837, 0.01994736, 0.01337273, 0.02863505, 0.02018907,\n",
      "       0.04201503, 0.03194909, 0.02019739, 0.01449392, 0.03511946,\n",
      "       0.02538254, 0.04830482, 0.0433181 , 0.02172155, 0.0119458 ,\n",
      "       0.02992582, 0.02037895, 0.05108922, 0.05139697, 0.02788935,\n",
      "       0.01442544, 0.03905151, 0.03334632, 0.04419484, 0.04055781,\n",
      "       0.02466924, 0.01312866, 0.03405027, 0.02550435, 0.04927084,\n",
      "       0.03772595, 0.02420921, 0.01394424, 0.03195832, 0.02223253,\n",
      "       0.05128117, 0.03627737, 0.02621257, 0.0155045 , 0.03076649,\n",
      "       0.02120109, 0.05119598, 0.03906639, 0.01933911, 0.01456316,\n",
      "       0.03610351, 0.02602952, 0.04676015, 0.0508589 , 0.02946739,\n",
      "       0.0178746 , 0.03342066, 0.02136955, 0.04779723, 0.04191647,\n",
      "       0.02085571, 0.01316299, 0.03168938, 0.02114522, 0.04697614,\n",
      "       0.03610427, 0.02169361, 0.01505027, 0.03826351, 0.02533088,\n",
      "       0.05415645, 0.04091785, 0.02442255, 0.01507604, 0.03089738,\n",
      "       0.02043924, 0.04847565, 0.03526418, 0.02321165, 0.01343148,\n",
      "       0.02947674, 0.02086413, 0.04821076, 0.0379916 , 0.02231445,\n",
      "       0.01515927, 0.03540533, 0.02376726, 0.05828974, 0.04244235,\n",
      "       0.02453463, 0.01477313, 0.03251207, 0.01934566, 0.04617875,\n",
      "       0.03709228, 0.02049294, 0.0133677 , 0.02665091, 0.02004709,\n",
      "       0.0443234 , 0.03228698, 0.01930413, 0.01376479, 0.03395367,\n",
      "       0.0243073 , 0.05189834, 0.04159968, 0.02343402, 0.0133637 ,\n",
      "       0.03500586, 0.02283931, 0.04819312, 0.03791919, 0.02216148,\n",
      "       0.01338966, 0.02992382, 0.02128329, 0.045802  , 0.03404024,\n",
      "       0.02134581, 0.0138643 , 0.03540494, 0.02289693, 0.04928217,\n",
      "       0.03891795, 0.02381814, 0.01371076, 0.03296773, 0.02383821,\n",
      "       0.04652739, 0.03734896, 0.02219088, 0.01437461, 0.03205235,\n",
      "       0.02219684, 0.04403248, 0.03575494, 0.01989989, 0.01443632,\n",
      "       0.03856933, 0.02492383, 0.05028107, 0.04016149, 0.02456253,\n",
      "       0.01512322, 0.03375704, 0.02181437, 0.05109653, 0.03910809,\n",
      "       0.0235815 , 0.01327085, 0.03348551, 0.02432468, 0.04653122,\n",
      "       0.03485069, 0.02628837, 0.02124324, 0.03688381, 0.02647557,\n",
      "       0.04812863, 0.03933594, 0.02378421, 0.01395559, 0.03261192,\n",
      "       0.02144501, 0.05649073, 0.04318998, 0.0238301 , 0.01364849,\n",
      "       0.03041866, 0.02313817, 0.04662769, 0.04036396, 0.01972206,\n",
      "       0.01417739, 0.03529975, 0.02504351, 0.04953904, 0.04850576,\n",
      "       0.02489195, 0.01470444, 0.03274107, 0.02221959, 0.05258713,\n",
      "       0.04819779, 0.02173791, 0.01392937, 0.03698869, 0.02264886,\n",
      "       0.04993641, 0.03753648, 0.02215984, 0.01405215, 0.03660672,\n",
      "       0.02500889, 0.05660129, 0.04635639, 0.02564313, 0.01396034,\n",
      "       0.0292217 , 0.02043529, 0.0464756 , 0.03160489, 0.01989543,\n",
      "       0.01320658, 0.02699182, 0.02036536, 0.04563682, 0.03454027,\n",
      "       0.01921206, 0.01336713, 0.03340969, 0.02333758, 0.04644499,\n",
      "       0.04213901, 0.0218873 , 0.01246972, 0.03229055, 0.0225842 ,\n",
      "       0.04524157, 0.03509028, 0.02366512, 0.01325963, 0.03161466,\n",
      "       0.02412751, 0.04722435, 0.03718638, 0.02264447, 0.01440792,\n",
      "       0.03460484, 0.02230647, 0.04899611, 0.03777974, 0.02472339,\n",
      "       0.01304119, 0.0329402 , 0.0206867 , 0.05600462, 0.03964968,\n",
      "       0.02539511, 0.01727288, 0.04039114, 0.02623262, 0.06088321,\n",
      "       0.0427737 , 0.0223618 , 0.01595545, 0.03854709, 0.02712626,\n",
      "       0.04928806, 0.04719923, 0.02581394, 0.01398184, 0.03251317,\n",
      "       0.02154109, 0.05058963, 0.03595991, 0.02186143, 0.01408885,\n",
      "       0.03054764, 0.02245831, 0.04910047, 0.03530278, 0.020748  ,\n",
      "       0.01336646, 0.03599825, 0.02159486, 0.04857011, 0.04218948,\n",
      "       0.02623193, 0.01366665, 0.03114936, 0.02350266, 0.05666425,\n",
      "       0.03965156, 0.02009246, 0.01277692, 0.03167956, 0.02185516,\n",
      "       0.04410238, 0.04155347, 0.02138996, 0.01520855, 0.03539221,\n",
      "       0.02624133, 0.05865526, 0.03969498, 0.02687824, 0.014833  ,\n",
      "       0.03957145, 0.02518489, 0.05132244, 0.03520434, 0.0223639 ,\n",
      "       0.01420507, 0.03153117, 0.02307165, 0.04712501, 0.03745461,\n",
      "       0.02182541, 0.01296942, 0.03689992, 0.02413857, 0.05400271,\n",
      "       0.04327824, 0.02637506, 0.01457002, 0.02710419, 0.02013652,\n",
      "       0.04571667, 0.0340219 , 0.01728611, 0.0134181 , 0.02909701,\n",
      "       0.02009568, 0.04284418, 0.04024048, 0.02254806]), 'std_score_time': array([0.00375282, 0.00393228, 0.00282482, 0.00889726, 0.00513586,\n",
      "       0.00516149, 0.00294214, 0.00239402, 0.00346034, 0.00465631,\n",
      "       0.00709171, 0.00291551, 0.00306735, 0.00186175, 0.00285736,\n",
      "       0.00730053, 0.00439577, 0.00405661, 0.00194741, 0.00543218,\n",
      "       0.00371258, 0.00923379, 0.01255353, 0.00567348, 0.00142442,\n",
      "       0.0030833 , 0.00306556, 0.00858418, 0.01236512, 0.01207507,\n",
      "       0.00174682, 0.00985677, 0.00855829, 0.00277555, 0.01220107,\n",
      "       0.00716297, 0.00241608, 0.00276347, 0.00184551, 0.00480274,\n",
      "       0.00161332, 0.00375007, 0.00271271, 0.00211752, 0.00315983,\n",
      "       0.00879695, 0.00231672, 0.0069382 , 0.00384603, 0.0016701 ,\n",
      "       0.00241346, 0.01169912, 0.01044577, 0.0031835 , 0.00331204,\n",
      "       0.0015957 , 0.0027296 , 0.00297373, 0.01536354, 0.00617299,\n",
      "       0.00383238, 0.00445387, 0.00306445, 0.00538874, 0.01008285,\n",
      "       0.00413021, 0.00247827, 0.00182484, 0.00263247, 0.00662512,\n",
      "       0.00326968, 0.0030996 , 0.00277895, 0.00252664, 0.00282303,\n",
      "       0.00909587, 0.0019563 , 0.00391654, 0.00317747, 0.00206936,\n",
      "       0.00319198, 0.00716849, 0.00391787, 0.00754066, 0.00263108,\n",
      "       0.00345961, 0.00240512, 0.00856182, 0.00663511, 0.00211217,\n",
      "       0.00270513, 0.002193  , 0.00324424, 0.00983648, 0.00229601,\n",
      "       0.00370753, 0.00459503, 0.00381531, 0.00245465, 0.00262794,\n",
      "       0.00292997, 0.00439958, 0.00289829, 0.00284704, 0.00287219,\n",
      "       0.00183414, 0.00334998, 0.00395034, 0.00308344, 0.00243428,\n",
      "       0.00257522, 0.00911438, 0.00833699, 0.00615217, 0.0024507 ,\n",
      "       0.00719956, 0.00530501, 0.00560854, 0.00555283, 0.00420202,\n",
      "       0.0027261 , 0.0023823 , 0.0042025 , 0.0055062 , 0.00274816,\n",
      "       0.0030528 , 0.00303934, 0.00232844, 0.00247151, 0.0090067 ,\n",
      "       0.00487115, 0.00278258, 0.00255925, 0.00356891, 0.00242039,\n",
      "       0.00530609, 0.00275355, 0.0014814 , 0.00330168, 0.00213386,\n",
      "       0.00304243, 0.00320036, 0.00533273, 0.00368093, 0.00310106,\n",
      "       0.00303617, 0.00215849, 0.00702117, 0.00384982, 0.00369161,\n",
      "       0.00292498, 0.00183272, 0.00279651, 0.00979404, 0.00315246,\n",
      "       0.00695073, 0.00280515, 0.00269204, 0.00229686, 0.00704742,\n",
      "       0.00235877, 0.00638709, 0.00616354, 0.00746337, 0.0030569 ,\n",
      "       0.00420733, 0.00430984, 0.0031882 , 0.00259417, 0.00209427,\n",
      "       0.00241197, 0.00979161, 0.00680535, 0.00371459, 0.00352113,\n",
      "       0.00195651, 0.00177307, 0.00841977, 0.00864751, 0.00379373,\n",
      "       0.00278204, 0.0019602 , 0.00246596, 0.00379343, 0.01254651,\n",
      "       0.00546279, 0.00282092, 0.00203004, 0.0038946 , 0.01326528,\n",
      "       0.01063129, 0.003975  , 0.00221123, 0.00712191, 0.00403906,\n",
      "       0.00849962, 0.00456435, 0.00302488, 0.00243115, 0.00550926,\n",
      "       0.00354053, 0.00693474, 0.00945126, 0.00341518, 0.00227308,\n",
      "       0.00330881, 0.00273804, 0.00149205, 0.00381693, 0.00315332,\n",
      "       0.00267067, 0.00364351, 0.00351599, 0.00193557, 0.00283709,\n",
      "       0.00303631, 0.00162143, 0.00219633, 0.00279252, 0.00429859,\n",
      "       0.00796036, 0.00401764, 0.00173942, 0.00240333, 0.00215401,\n",
      "       0.00262778, 0.00537366, 0.00856823, 0.00223649, 0.00214021,\n",
      "       0.0016125 , 0.00654956, 0.00509786, 0.00424736, 0.00273088,\n",
      "       0.00261396, 0.00370015, 0.0047866 , 0.002986  , 0.0088172 ,\n",
      "       0.00295911, 0.00434552, 0.0022878 , 0.01028593, 0.00796016,\n",
      "       0.00286561, 0.00307188, 0.01240976, 0.00427914, 0.01598665,\n",
      "       0.00558994, 0.00288061, 0.00418747, 0.00310812, 0.00452686,\n",
      "       0.0038086 , 0.0080503 , 0.00346417, 0.00304102, 0.00260464,\n",
      "       0.00282799, 0.00709259, 0.0035917 , 0.00430749, 0.00243321,\n",
      "       0.00272408, 0.00232359, 0.00785701, 0.00460965, 0.00348258,\n",
      "       0.00219733, 0.00158581, 0.00230386, 0.00373207, 0.00573401,\n",
      "       0.00381014, 0.00310299, 0.00267826, 0.00239711, 0.01258505,\n",
      "       0.00873877, 0.00365238, 0.00288575, 0.00198619, 0.00222861,\n",
      "       0.00345821, 0.01111122, 0.00374064, 0.00284921, 0.00288392,\n",
      "       0.00220632, 0.01329268, 0.00176098, 0.00195182, 0.00298335,\n",
      "       0.00687782, 0.00288028, 0.00881919, 0.00292008, 0.00386496,\n",
      "       0.00229394, 0.0017596 , 0.00265537, 0.00754468, 0.00626758,\n",
      "       0.00359613, 0.00278415, 0.00205479, 0.0032988 , 0.00541723,\n",
      "       0.00418895, 0.00683455, 0.00289669, 0.00435645, 0.00306053,\n",
      "       0.00185048, 0.00260992, 0.00265091, 0.0028307 , 0.0027639 ,\n",
      "       0.00291051, 0.00278382, 0.01216062, 0.00756968]), 'param_vectorizer__analyzer': masked_array(data=['word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word', 'word', 'word', 'word', 'word', 'word',\n",
      "                   'word', 'word'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_vectorizer__max_df': masked_array(data=[0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "                   0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_vectorizer__max_features': masked_array(data=[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
      "                   10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
      "                   10000, 10000, 15000, 15000, 15000, 15000, 15000, 15000,\n",
      "                   15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,\n",
      "                   15000, 15000, 15000, 15000, 20000, 20000, 20000, 20000,\n",
      "                   20000, 20000, 20000, 20000, 20000, 20000, 20000, 20000,\n",
      "                   20000, 20000, 20000, 20000, 20000, 20000, 25000, 25000,\n",
      "                   25000, 25000, 25000, 25000, 25000, 25000, 25000, 25000,\n",
      "                   25000, 25000, 25000, 25000, 25000, 25000, 25000, 25000,\n",
      "                   30000, 30000, 30000, 30000, 30000, 30000, 30000, 30000,\n",
      "                   30000, 30000, 30000, 30000, 30000, 30000, 30000, 30000,\n",
      "                   30000, 30000, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, 10000, 10000, 10000, 10000, 10000, 10000,\n",
      "                   10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
      "                   10000, 10000, 10000, 10000, 15000, 15000, 15000, 15000,\n",
      "                   15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,\n",
      "                   15000, 15000, 15000, 15000, 15000, 15000, 20000, 20000,\n",
      "                   20000, 20000, 20000, 20000, 20000, 20000, 20000, 20000,\n",
      "                   20000, 20000, 20000, 20000, 20000, 20000, 20000, 20000,\n",
      "                   25000, 25000, 25000, 25000, 25000, 25000, 25000, 25000,\n",
      "                   25000, 25000, 25000, 25000, 25000, 25000, 25000, 25000,\n",
      "                   25000, 25000, 30000, 30000, 30000, 30000, 30000, 30000,\n",
      "                   30000, 30000, 30000, 30000, 30000, 30000, 30000, 30000,\n",
      "                   30000, 30000, 30000, 30000, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, 10000, 10000, 10000,\n",
      "                   10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,\n",
      "                   10000, 10000, 10000, 10000, 10000, 10000, 10000, 15000,\n",
      "                   15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,\n",
      "                   15000, 15000, 15000, 15000, 15000, 15000, 15000, 15000,\n",
      "                   15000, 20000, 20000, 20000, 20000, 20000, 20000, 20000,\n",
      "                   20000, 20000, 20000, 20000, 20000, 20000, 20000, 20000,\n",
      "                   20000, 20000, 20000, 25000, 25000, 25000, 25000, 25000,\n",
      "                   25000, 25000, 25000, 25000, 25000, 25000, 25000, 25000,\n",
      "                   25000, 25000, 25000, 25000, 25000, 30000, 30000, 30000,\n",
      "                   30000, 30000, 30000, 30000, 30000, 30000, 30000, 30000,\n",
      "                   30000, 30000, 30000, 30000, 30000, 30000, 30000, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_vectorizer__min_df': masked_array(data=[0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
      "                   10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5,\n",
      "                   5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0,\n",
      "                   5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 0, 0, 0, 0,\n",
      "                   0, 0, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 0, 0,\n",
      "                   0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
      "                   0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
      "                   10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
      "                   10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10, 10,\n",
      "                   10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 10,\n",
      "                   10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5,\n",
      "                   10, 10, 10, 10, 10, 10, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5,\n",
      "                   5, 5, 10, 10, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_vectorizer__ngram_range': masked_array(data=[(1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1),\n",
      "                   (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2),\n",
      "                   (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2),\n",
      "                   (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3),\n",
      "                   (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3),\n",
      "                   (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3),\n",
      "                   (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1),\n",
      "                   (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2),\n",
      "                   (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2),\n",
      "                   (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3),\n",
      "                   (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3),\n",
      "                   (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3),\n",
      "                   (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1),\n",
      "                   (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2),\n",
      "                   (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2),\n",
      "                   (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3),\n",
      "                   (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3),\n",
      "                   (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3),\n",
      "                   (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1),\n",
      "                   (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2),\n",
      "                   (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2),\n",
      "                   (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3),\n",
      "                   (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3),\n",
      "                   (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3),\n",
      "                   (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1),\n",
      "                   (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2),\n",
      "                   (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2),\n",
      "                   (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3),\n",
      "                   (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3),\n",
      "                   (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3),\n",
      "                   (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1),\n",
      "                   (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2),\n",
      "                   (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2),\n",
      "                   (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3),\n",
      "                   (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3),\n",
      "                   (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3),\n",
      "                   (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1),\n",
      "                   (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2),\n",
      "                   (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2),\n",
      "                   (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3),\n",
      "                   (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3),\n",
      "                   (3, 3), (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3),\n",
      "                   (1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1),\n",
      "                   (1, 2), (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2),\n",
      "                   (2, 2), (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2),\n",
      "                   (1, 3), (2, 3), (3, 3), (1, 1), (1, 2), (2, 2), (1, 3),\n",
      "                   (2, 3), (3, 3)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.95, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 15000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 20000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 25000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': 30000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (3, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 2)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (2, 3)}, {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 1.0, 'vectorizer__max_features': None, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (3, 3)}], 'split0_test_score': array([0.83395291, 0.83023544, 0.79677819, 0.8228005 , 0.77695167,\n",
      "       0.73110285, 0.755886  , 0.78438662, 0.70136307, 0.78686493,\n",
      "       0.70508055, 0.6307311 , 0.74349442, 0.76703841, 0.65675341,\n",
      "       0.7645601 , 0.65427509, 0.60594796, 0.83395291, 0.85006196,\n",
      "       0.83271375, 0.83023544, 0.79553903, 0.78066914, 0.755886  ,\n",
      "       0.78438662, 0.70136307, 0.78686493, 0.70508055, 0.6307311 ,\n",
      "       0.74349442, 0.76703841, 0.65675341, 0.7645601 , 0.65427509,\n",
      "       0.60594796, 0.83395291, 0.866171  , 0.86864932, 0.82775713,\n",
      "       0.81040892, 0.85254027, 0.755886  , 0.78438662, 0.70136307,\n",
      "       0.78686493, 0.70508055, 0.6307311 , 0.74349442, 0.76703841,\n",
      "       0.65675341, 0.7645601 , 0.65427509, 0.60594796, 0.83395291,\n",
      "       0.88351921, 0.88723668, 0.85130112, 0.83395291, 0.88104089,\n",
      "       0.755886  , 0.78438662, 0.70136307, 0.78686493, 0.70508055,\n",
      "       0.6307311 , 0.74349442, 0.76703841, 0.65675341, 0.7645601 ,\n",
      "       0.65427509, 0.60594796, 0.83395291, 0.89962825, 0.89343247,\n",
      "       0.86121437, 0.84138786, 0.88599752, 0.755886  , 0.78438662,\n",
      "       0.70136307, 0.78686493, 0.70508055, 0.6307311 , 0.74349442,\n",
      "       0.76703841, 0.65675341, 0.7645601 , 0.65427509, 0.60594796,\n",
      "       0.83395291, 0.90830235, 0.89343247, 0.91449814, 0.89962825,\n",
      "       0.88847584, 0.755886  , 0.78438662, 0.70136307, 0.78686493,\n",
      "       0.70508055, 0.6307311 , 0.74349442, 0.76703841, 0.65675341,\n",
      "       0.7645601 , 0.65427509, 0.60594796, 0.83395291, 0.83023544,\n",
      "       0.79677819, 0.8228005 , 0.77695167, 0.73110285, 0.755886  ,\n",
      "       0.78438662, 0.70136307, 0.78686493, 0.70508055, 0.6307311 ,\n",
      "       0.74349442, 0.76703841, 0.65675341, 0.7645601 , 0.65427509,\n",
      "       0.60594796, 0.83395291, 0.85006196, 0.83271375, 0.83023544,\n",
      "       0.79553903, 0.78066914, 0.755886  , 0.78438662, 0.70136307,\n",
      "       0.78686493, 0.70508055, 0.6307311 , 0.74349442, 0.76703841,\n",
      "       0.65675341, 0.7645601 , 0.65427509, 0.60594796, 0.83395291,\n",
      "       0.866171  , 0.86864932, 0.82775713, 0.81040892, 0.85254027,\n",
      "       0.755886  , 0.78438662, 0.70136307, 0.78686493, 0.70508055,\n",
      "       0.6307311 , 0.74349442, 0.76703841, 0.65675341, 0.7645601 ,\n",
      "       0.65427509, 0.60594796, 0.83395291, 0.88351921, 0.88723668,\n",
      "       0.85130112, 0.83395291, 0.88104089, 0.755886  , 0.78438662,\n",
      "       0.70136307, 0.78686493, 0.70508055, 0.6307311 , 0.74349442,\n",
      "       0.76703841, 0.65675341, 0.7645601 , 0.65427509, 0.60594796,\n",
      "       0.83395291, 0.89962825, 0.89343247, 0.86121437, 0.84138786,\n",
      "       0.88599752, 0.755886  , 0.78438662, 0.70136307, 0.78686493,\n",
      "       0.70508055, 0.6307311 , 0.74349442, 0.76703841, 0.65675341,\n",
      "       0.7645601 , 0.65427509, 0.60594796, 0.83395291, 0.90830235,\n",
      "       0.89343247, 0.91449814, 0.89962825, 0.88847584, 0.755886  ,\n",
      "       0.78438662, 0.70136307, 0.78686493, 0.70508055, 0.6307311 ,\n",
      "       0.74349442, 0.76703841, 0.65675341, 0.7645601 , 0.65427509,\n",
      "       0.60594796, 0.83395291, 0.83023544, 0.79677819, 0.8228005 ,\n",
      "       0.77695167, 0.73110285, 0.755886  , 0.78438662, 0.70136307,\n",
      "       0.78686493, 0.70508055, 0.6307311 , 0.74349442, 0.76703841,\n",
      "       0.65675341, 0.7645601 , 0.65427509, 0.60594796, 0.83395291,\n",
      "       0.85006196, 0.83271375, 0.83023544, 0.79553903, 0.78066914,\n",
      "       0.755886  , 0.78438662, 0.70136307, 0.78686493, 0.70508055,\n",
      "       0.6307311 , 0.74349442, 0.76703841, 0.65675341, 0.7645601 ,\n",
      "       0.65427509, 0.60594796, 0.83395291, 0.866171  , 0.86864932,\n",
      "       0.82775713, 0.81040892, 0.85254027, 0.755886  , 0.78438662,\n",
      "       0.70136307, 0.78686493, 0.70508055, 0.6307311 , 0.74349442,\n",
      "       0.76703841, 0.65675341, 0.7645601 , 0.65427509, 0.60594796,\n",
      "       0.83395291, 0.88351921, 0.88723668, 0.85130112, 0.83395291,\n",
      "       0.88104089, 0.755886  , 0.78438662, 0.70136307, 0.78686493,\n",
      "       0.70508055, 0.6307311 , 0.74349442, 0.76703841, 0.65675341,\n",
      "       0.7645601 , 0.65427509, 0.60594796, 0.83395291, 0.89962825,\n",
      "       0.89343247, 0.86121437, 0.84138786, 0.88599752, 0.755886  ,\n",
      "       0.78438662, 0.70136307, 0.78686493, 0.70508055, 0.6307311 ,\n",
      "       0.74349442, 0.76703841, 0.65675341, 0.7645601 , 0.65427509,\n",
      "       0.60594796, 0.83395291, 0.90830235, 0.89343247, 0.91449814,\n",
      "       0.89962825, 0.88847584, 0.755886  , 0.78438662, 0.70136307,\n",
      "       0.78686493, 0.70508055, 0.6307311 , 0.74349442, 0.76703841,\n",
      "       0.65675341, 0.7645601 , 0.65427509, 0.60594796]), 'split1_test_score': array([0.83767038, 0.82899628, 0.7905824 , 0.83023544, 0.77075589,\n",
      "       0.73234201, 0.77199504, 0.7905824 , 0.6889715 , 0.79306072,\n",
      "       0.6976456 , 0.61090458, 0.73605948, 0.74845105, 0.61957869,\n",
      "       0.7472119 , 0.62081784, 0.59479554, 0.83767038, 0.85254027,\n",
      "       0.82899628, 0.82775713, 0.78438662, 0.77942999, 0.77199504,\n",
      "       0.7905824 , 0.6889715 , 0.79306072, 0.6976456 , 0.61090458,\n",
      "       0.73605948, 0.74845105, 0.61957869, 0.7472119 , 0.62081784,\n",
      "       0.59479554, 0.83767038, 0.87484511, 0.86245353, 0.83767038,\n",
      "       0.81164808, 0.8574969 , 0.77199504, 0.7905824 , 0.6889715 ,\n",
      "       0.79306072, 0.6976456 , 0.61090458, 0.73605948, 0.74845105,\n",
      "       0.61957869, 0.7472119 , 0.62081784, 0.59479554, 0.83767038,\n",
      "       0.88475836, 0.88104089, 0.85377943, 0.82527881, 0.87484511,\n",
      "       0.77199504, 0.7905824 , 0.6889715 , 0.79306072, 0.6976456 ,\n",
      "       0.61090458, 0.73605948, 0.74845105, 0.61957869, 0.7472119 ,\n",
      "       0.62081784, 0.59479554, 0.83767038, 0.89714994, 0.88847584,\n",
      "       0.87112763, 0.82899628, 0.87732342, 0.77199504, 0.7905824 ,\n",
      "       0.6889715 , 0.79306072, 0.6976456 , 0.61090458, 0.73605948,\n",
      "       0.74845105, 0.61957869, 0.7472119 , 0.62081784, 0.59479554,\n",
      "       0.83767038, 0.90582404, 0.88847584, 0.91325898, 0.88723668,\n",
      "       0.87732342, 0.77199504, 0.7905824 , 0.6889715 , 0.79306072,\n",
      "       0.6976456 , 0.61090458, 0.73605948, 0.74845105, 0.61957869,\n",
      "       0.7472119 , 0.62081784, 0.59479554, 0.83767038, 0.82899628,\n",
      "       0.7905824 , 0.83023544, 0.77075589, 0.73234201, 0.77199504,\n",
      "       0.7905824 , 0.6889715 , 0.79306072, 0.6976456 , 0.61090458,\n",
      "       0.73605948, 0.74845105, 0.61957869, 0.7472119 , 0.62081784,\n",
      "       0.59479554, 0.83767038, 0.85254027, 0.82899628, 0.82775713,\n",
      "       0.78438662, 0.77942999, 0.77199504, 0.7905824 , 0.6889715 ,\n",
      "       0.79306072, 0.6976456 , 0.61090458, 0.73605948, 0.74845105,\n",
      "       0.61957869, 0.7472119 , 0.62081784, 0.59479554, 0.83767038,\n",
      "       0.87484511, 0.86245353, 0.83767038, 0.81164808, 0.8574969 ,\n",
      "       0.77199504, 0.7905824 , 0.6889715 , 0.79306072, 0.6976456 ,\n",
      "       0.61090458, 0.73605948, 0.74845105, 0.61957869, 0.7472119 ,\n",
      "       0.62081784, 0.59479554, 0.83767038, 0.88475836, 0.88104089,\n",
      "       0.85377943, 0.82527881, 0.87484511, 0.77199504, 0.7905824 ,\n",
      "       0.6889715 , 0.79306072, 0.6976456 , 0.61090458, 0.73605948,\n",
      "       0.74845105, 0.61957869, 0.7472119 , 0.62081784, 0.59479554,\n",
      "       0.83767038, 0.89714994, 0.88847584, 0.87112763, 0.82899628,\n",
      "       0.87732342, 0.77199504, 0.7905824 , 0.6889715 , 0.79306072,\n",
      "       0.6976456 , 0.61090458, 0.73605948, 0.74845105, 0.61957869,\n",
      "       0.7472119 , 0.62081784, 0.59479554, 0.83767038, 0.90582404,\n",
      "       0.88847584, 0.91325898, 0.88723668, 0.87732342, 0.77199504,\n",
      "       0.7905824 , 0.6889715 , 0.79306072, 0.6976456 , 0.61090458,\n",
      "       0.73605948, 0.74845105, 0.61957869, 0.7472119 , 0.62081784,\n",
      "       0.59479554, 0.83767038, 0.82899628, 0.7905824 , 0.83023544,\n",
      "       0.77075589, 0.73234201, 0.77199504, 0.7905824 , 0.6889715 ,\n",
      "       0.79306072, 0.6976456 , 0.61090458, 0.73605948, 0.74845105,\n",
      "       0.61957869, 0.7472119 , 0.62081784, 0.59479554, 0.83767038,\n",
      "       0.85254027, 0.82899628, 0.82775713, 0.78438662, 0.77942999,\n",
      "       0.77199504, 0.7905824 , 0.6889715 , 0.79306072, 0.6976456 ,\n",
      "       0.61090458, 0.73605948, 0.74845105, 0.61957869, 0.7472119 ,\n",
      "       0.62081784, 0.59479554, 0.83767038, 0.87484511, 0.86245353,\n",
      "       0.83767038, 0.81164808, 0.8574969 , 0.77199504, 0.7905824 ,\n",
      "       0.6889715 , 0.79306072, 0.6976456 , 0.61090458, 0.73605948,\n",
      "       0.74845105, 0.61957869, 0.7472119 , 0.62081784, 0.59479554,\n",
      "       0.83767038, 0.88475836, 0.88104089, 0.85377943, 0.82527881,\n",
      "       0.87484511, 0.77199504, 0.7905824 , 0.6889715 , 0.79306072,\n",
      "       0.6976456 , 0.61090458, 0.73605948, 0.74845105, 0.61957869,\n",
      "       0.7472119 , 0.62081784, 0.59479554, 0.83767038, 0.89714994,\n",
      "       0.88847584, 0.87112763, 0.82899628, 0.87732342, 0.77199504,\n",
      "       0.7905824 , 0.6889715 , 0.79306072, 0.6976456 , 0.61090458,\n",
      "       0.73605948, 0.74845105, 0.61957869, 0.7472119 , 0.62081784,\n",
      "       0.59479554, 0.83767038, 0.90582404, 0.88847584, 0.91325898,\n",
      "       0.88723668, 0.87732342, 0.77199504, 0.7905824 , 0.6889715 ,\n",
      "       0.79306072, 0.6976456 , 0.61090458, 0.73605948, 0.74845105,\n",
      "       0.61957869, 0.7472119 , 0.62081784, 0.59479554]), 'split2_test_score': array([0.80545229, 0.83271375, 0.80173482, 0.82651797, 0.79182156,\n",
      "       0.75960347, 0.77571252, 0.79801735, 0.71871128, 0.79429988,\n",
      "       0.72242875, 0.62577447, 0.75712515, 0.76332094, 0.64931846,\n",
      "       0.7645601 , 0.65179678, 0.60346964, 0.80545229, 0.85130112,\n",
      "       0.8488228 , 0.83271375, 0.80049566, 0.79429988, 0.77571252,\n",
      "       0.79801735, 0.71871128, 0.79429988, 0.72242875, 0.62577447,\n",
      "       0.75712515, 0.76332094, 0.64931846, 0.7645601 , 0.65179678,\n",
      "       0.60346964, 0.80545229, 0.86741016, 0.87732342, 0.83767038,\n",
      "       0.81908302, 0.87112763, 0.77571252, 0.79801735, 0.71871128,\n",
      "       0.79429988, 0.72242875, 0.62577447, 0.75712515, 0.76332094,\n",
      "       0.64931846, 0.7645601 , 0.65179678, 0.60346964, 0.80545229,\n",
      "       0.88104089, 0.90086741, 0.85377943, 0.84758364, 0.90334572,\n",
      "       0.77571252, 0.79801735, 0.71871128, 0.79429988, 0.72242875,\n",
      "       0.62577447, 0.75712515, 0.76332094, 0.64931846, 0.7645601 ,\n",
      "       0.65179678, 0.60346964, 0.80545229, 0.89095415, 0.90334572,\n",
      "       0.86864932, 0.85625774, 0.90582404, 0.77571252, 0.79801735,\n",
      "       0.71871128, 0.79429988, 0.72242875, 0.62577447, 0.75712515,\n",
      "       0.76332094, 0.64931846, 0.7645601 , 0.65179678, 0.60346964,\n",
      "       0.80545229, 0.90086741, 0.90334572, 0.90954151, 0.90582404,\n",
      "       0.90582404, 0.77571252, 0.79801735, 0.71871128, 0.79429988,\n",
      "       0.72242875, 0.62577447, 0.75712515, 0.76332094, 0.64931846,\n",
      "       0.7645601 , 0.65179678, 0.60346964, 0.80545229, 0.83271375,\n",
      "       0.80173482, 0.82651797, 0.79182156, 0.75960347, 0.77571252,\n",
      "       0.79801735, 0.71871128, 0.79429988, 0.72242875, 0.62577447,\n",
      "       0.75712515, 0.76332094, 0.64931846, 0.7645601 , 0.65179678,\n",
      "       0.60346964, 0.80545229, 0.85130112, 0.8488228 , 0.83271375,\n",
      "       0.80049566, 0.79429988, 0.77571252, 0.79801735, 0.71871128,\n",
      "       0.79429988, 0.72242875, 0.62577447, 0.75712515, 0.76332094,\n",
      "       0.64931846, 0.7645601 , 0.65179678, 0.60346964, 0.80545229,\n",
      "       0.86741016, 0.87732342, 0.83767038, 0.81908302, 0.87112763,\n",
      "       0.77571252, 0.79801735, 0.71871128, 0.79429988, 0.72242875,\n",
      "       0.62577447, 0.75712515, 0.76332094, 0.64931846, 0.7645601 ,\n",
      "       0.65179678, 0.60346964, 0.80545229, 0.88104089, 0.90086741,\n",
      "       0.85377943, 0.84758364, 0.90334572, 0.77571252, 0.79801735,\n",
      "       0.71871128, 0.79429988, 0.72242875, 0.62577447, 0.75712515,\n",
      "       0.76332094, 0.64931846, 0.7645601 , 0.65179678, 0.60346964,\n",
      "       0.80545229, 0.89095415, 0.90334572, 0.86864932, 0.85625774,\n",
      "       0.90582404, 0.77571252, 0.79801735, 0.71871128, 0.79429988,\n",
      "       0.72242875, 0.62577447, 0.75712515, 0.76332094, 0.64931846,\n",
      "       0.7645601 , 0.65179678, 0.60346964, 0.80545229, 0.90086741,\n",
      "       0.90334572, 0.90954151, 0.90582404, 0.90582404, 0.77571252,\n",
      "       0.79801735, 0.71871128, 0.79429988, 0.72242875, 0.62577447,\n",
      "       0.75712515, 0.76332094, 0.64931846, 0.7645601 , 0.65179678,\n",
      "       0.60346964, 0.80545229, 0.83271375, 0.80173482, 0.82651797,\n",
      "       0.79182156, 0.75960347, 0.77571252, 0.79801735, 0.71871128,\n",
      "       0.79429988, 0.72242875, 0.62577447, 0.75712515, 0.76332094,\n",
      "       0.64931846, 0.7645601 , 0.65179678, 0.60346964, 0.80545229,\n",
      "       0.85130112, 0.8488228 , 0.83271375, 0.80049566, 0.79429988,\n",
      "       0.77571252, 0.79801735, 0.71871128, 0.79429988, 0.72242875,\n",
      "       0.62577447, 0.75712515, 0.76332094, 0.64931846, 0.7645601 ,\n",
      "       0.65179678, 0.60346964, 0.80545229, 0.86741016, 0.87732342,\n",
      "       0.83767038, 0.81908302, 0.87112763, 0.77571252, 0.79801735,\n",
      "       0.71871128, 0.79429988, 0.72242875, 0.62577447, 0.75712515,\n",
      "       0.76332094, 0.64931846, 0.7645601 , 0.65179678, 0.60346964,\n",
      "       0.80545229, 0.88104089, 0.90086741, 0.85377943, 0.84758364,\n",
      "       0.90334572, 0.77571252, 0.79801735, 0.71871128, 0.79429988,\n",
      "       0.72242875, 0.62577447, 0.75712515, 0.76332094, 0.64931846,\n",
      "       0.7645601 , 0.65179678, 0.60346964, 0.80545229, 0.89095415,\n",
      "       0.90334572, 0.86864932, 0.85625774, 0.90582404, 0.77571252,\n",
      "       0.79801735, 0.71871128, 0.79429988, 0.72242875, 0.62577447,\n",
      "       0.75712515, 0.76332094, 0.64931846, 0.7645601 , 0.65179678,\n",
      "       0.60346964, 0.80545229, 0.90086741, 0.90334572, 0.90954151,\n",
      "       0.90582404, 0.90582404, 0.77571252, 0.79801735, 0.71871128,\n",
      "       0.79429988, 0.72242875, 0.62577447, 0.75712515, 0.76332094,\n",
      "       0.64931846, 0.7645601 , 0.65179678, 0.60346964]), 'split3_test_score': array([0.8228005 , 0.84386617, 0.81040892, 0.8314746 , 0.77695167,\n",
      "       0.73853779, 0.76827757, 0.79677819, 0.71623296, 0.79925651,\n",
      "       0.71871128, 0.63568773, 0.74845105, 0.76579926, 0.65055762,\n",
      "       0.75960347, 0.64931846, 0.60594796, 0.8228005 , 0.85501859,\n",
      "       0.85625774, 0.84386617, 0.79429988, 0.77571252, 0.76827757,\n",
      "       0.79677819, 0.71623296, 0.79925651, 0.71871128, 0.63568773,\n",
      "       0.74845105, 0.76579926, 0.65055762, 0.75960347, 0.64931846,\n",
      "       0.60594796, 0.8228005 , 0.86864932, 0.88104089, 0.8401487 ,\n",
      "       0.82403965, 0.85006196, 0.76827757, 0.79677819, 0.71623296,\n",
      "       0.79925651, 0.71871128, 0.63568773, 0.74845105, 0.76579926,\n",
      "       0.65055762, 0.75960347, 0.64931846, 0.60594796, 0.8228005 ,\n",
      "       0.88104089, 0.90582404, 0.84758364, 0.84634449, 0.87732342,\n",
      "       0.76827757, 0.79677819, 0.71623296, 0.79925651, 0.71871128,\n",
      "       0.63568773, 0.74845105, 0.76579926, 0.65055762, 0.75960347,\n",
      "       0.64931846, 0.60594796, 0.8228005 , 0.89591078, 0.9070632 ,\n",
      "       0.86369269, 0.86369269, 0.88475836, 0.76827757, 0.79677819,\n",
      "       0.71623296, 0.79925651, 0.71871128, 0.63568773, 0.74845105,\n",
      "       0.76579926, 0.65055762, 0.75960347, 0.64931846, 0.60594796,\n",
      "       0.8228005 , 0.91201983, 0.9070632 , 0.92193309, 0.90458488,\n",
      "       0.88475836, 0.76827757, 0.79677819, 0.71623296, 0.79925651,\n",
      "       0.71871128, 0.63568773, 0.74845105, 0.76579926, 0.65055762,\n",
      "       0.75960347, 0.64931846, 0.60594796, 0.8228005 , 0.84386617,\n",
      "       0.81040892, 0.8314746 , 0.77695167, 0.73853779, 0.76827757,\n",
      "       0.79677819, 0.71623296, 0.79925651, 0.71871128, 0.63568773,\n",
      "       0.74845105, 0.76579926, 0.65055762, 0.75960347, 0.64931846,\n",
      "       0.60594796, 0.8228005 , 0.85501859, 0.85625774, 0.84386617,\n",
      "       0.79429988, 0.77571252, 0.76827757, 0.79677819, 0.71623296,\n",
      "       0.79925651, 0.71871128, 0.63568773, 0.74845105, 0.76579926,\n",
      "       0.65055762, 0.75960347, 0.64931846, 0.60594796, 0.8228005 ,\n",
      "       0.86864932, 0.88104089, 0.8401487 , 0.82403965, 0.85006196,\n",
      "       0.76827757, 0.79677819, 0.71623296, 0.79925651, 0.71871128,\n",
      "       0.63568773, 0.74845105, 0.76579926, 0.65055762, 0.75960347,\n",
      "       0.64931846, 0.60594796, 0.8228005 , 0.88104089, 0.90582404,\n",
      "       0.84758364, 0.84634449, 0.87732342, 0.76827757, 0.79677819,\n",
      "       0.71623296, 0.79925651, 0.71871128, 0.63568773, 0.74845105,\n",
      "       0.76579926, 0.65055762, 0.75960347, 0.64931846, 0.60594796,\n",
      "       0.8228005 , 0.89591078, 0.9070632 , 0.86369269, 0.86369269,\n",
      "       0.88475836, 0.76827757, 0.79677819, 0.71623296, 0.79925651,\n",
      "       0.71871128, 0.63568773, 0.74845105, 0.76579926, 0.65055762,\n",
      "       0.75960347, 0.64931846, 0.60594796, 0.8228005 , 0.91201983,\n",
      "       0.9070632 , 0.92193309, 0.90458488, 0.88475836, 0.76827757,\n",
      "       0.79677819, 0.71623296, 0.79925651, 0.71871128, 0.63568773,\n",
      "       0.74845105, 0.76579926, 0.65055762, 0.75960347, 0.64931846,\n",
      "       0.60594796, 0.8228005 , 0.84386617, 0.81040892, 0.8314746 ,\n",
      "       0.77695167, 0.73853779, 0.76827757, 0.79677819, 0.71623296,\n",
      "       0.79925651, 0.71871128, 0.63568773, 0.74845105, 0.76579926,\n",
      "       0.65055762, 0.75960347, 0.64931846, 0.60594796, 0.8228005 ,\n",
      "       0.85501859, 0.85625774, 0.84386617, 0.79429988, 0.77571252,\n",
      "       0.76827757, 0.79677819, 0.71623296, 0.79925651, 0.71871128,\n",
      "       0.63568773, 0.74845105, 0.76579926, 0.65055762, 0.75960347,\n",
      "       0.64931846, 0.60594796, 0.8228005 , 0.86864932, 0.88104089,\n",
      "       0.8401487 , 0.82403965, 0.85006196, 0.76827757, 0.79677819,\n",
      "       0.71623296, 0.79925651, 0.71871128, 0.63568773, 0.74845105,\n",
      "       0.76579926, 0.65055762, 0.75960347, 0.64931846, 0.60594796,\n",
      "       0.8228005 , 0.88104089, 0.90582404, 0.84758364, 0.84634449,\n",
      "       0.87732342, 0.76827757, 0.79677819, 0.71623296, 0.79925651,\n",
      "       0.71871128, 0.63568773, 0.74845105, 0.76579926, 0.65055762,\n",
      "       0.75960347, 0.64931846, 0.60594796, 0.8228005 , 0.89591078,\n",
      "       0.9070632 , 0.86369269, 0.86369269, 0.88475836, 0.76827757,\n",
      "       0.79677819, 0.71623296, 0.79925651, 0.71871128, 0.63568773,\n",
      "       0.74845105, 0.76579926, 0.65055762, 0.75960347, 0.64931846,\n",
      "       0.60594796, 0.8228005 , 0.91201983, 0.9070632 , 0.92193309,\n",
      "       0.90458488, 0.88475836, 0.76827757, 0.79677819, 0.71623296,\n",
      "       0.79925651, 0.71871128, 0.63568773, 0.74845105, 0.76579926,\n",
      "       0.65055762, 0.75960347, 0.64931846, 0.60594796]), 'split4_test_score': array([0.83023544, 0.85130112, 0.78810409, 0.85130112, 0.76951673,\n",
      "       0.74597274, 0.78066914, 0.81412639, 0.6976456 , 0.81412639,\n",
      "       0.70012392, 0.61462206, 0.75960347, 0.76827757, 0.64684015,\n",
      "       0.76827757, 0.64684015, 0.59231722, 0.83023544, 0.85625774,\n",
      "       0.83271375, 0.85006196, 0.78438662, 0.78314746, 0.78066914,\n",
      "       0.81412639, 0.6976456 , 0.81412639, 0.70012392, 0.61462206,\n",
      "       0.75960347, 0.76827757, 0.64684015, 0.76827757, 0.64684015,\n",
      "       0.59231722, 0.83023544, 0.87856258, 0.85873606, 0.85254027,\n",
      "       0.82651797, 0.84262701, 0.78066914, 0.81412639, 0.6976456 ,\n",
      "       0.81412639, 0.70012392, 0.61462206, 0.75960347, 0.76827757,\n",
      "       0.64684015, 0.76827757, 0.64684015, 0.59231722, 0.83023544,\n",
      "       0.89343247, 0.88723668, 0.86369269, 0.8314746 , 0.85997522,\n",
      "       0.78066914, 0.81412639, 0.6976456 , 0.81412639, 0.70012392,\n",
      "       0.61462206, 0.75960347, 0.76827757, 0.64684015, 0.76827757,\n",
      "       0.64684015, 0.59231722, 0.83023544, 0.90086741, 0.89219331,\n",
      "       0.88228005, 0.84510533, 0.86864932, 0.78066914, 0.81412639,\n",
      "       0.6976456 , 0.81412639, 0.70012392, 0.61462206, 0.75960347,\n",
      "       0.76827757, 0.64684015, 0.76827757, 0.64684015, 0.59231722,\n",
      "       0.83023544, 0.90582404, 0.89219331, 0.91821561, 0.89219331,\n",
      "       0.87112763, 0.78066914, 0.81412639, 0.6976456 , 0.81412639,\n",
      "       0.70012392, 0.61462206, 0.75960347, 0.76827757, 0.64684015,\n",
      "       0.76827757, 0.64684015, 0.59231722, 0.83023544, 0.85130112,\n",
      "       0.78810409, 0.85130112, 0.76951673, 0.74597274, 0.78066914,\n",
      "       0.81412639, 0.6976456 , 0.81412639, 0.70012392, 0.61462206,\n",
      "       0.75960347, 0.76827757, 0.64684015, 0.76827757, 0.64684015,\n",
      "       0.59231722, 0.83023544, 0.85625774, 0.83271375, 0.85006196,\n",
      "       0.78438662, 0.78314746, 0.78066914, 0.81412639, 0.6976456 ,\n",
      "       0.81412639, 0.70012392, 0.61462206, 0.75960347, 0.76827757,\n",
      "       0.64684015, 0.76827757, 0.64684015, 0.59231722, 0.83023544,\n",
      "       0.87856258, 0.85873606, 0.85254027, 0.82651797, 0.84262701,\n",
      "       0.78066914, 0.81412639, 0.6976456 , 0.81412639, 0.70012392,\n",
      "       0.61462206, 0.75960347, 0.76827757, 0.64684015, 0.76827757,\n",
      "       0.64684015, 0.59231722, 0.83023544, 0.89343247, 0.88723668,\n",
      "       0.86369269, 0.8314746 , 0.85997522, 0.78066914, 0.81412639,\n",
      "       0.6976456 , 0.81412639, 0.70012392, 0.61462206, 0.75960347,\n",
      "       0.76827757, 0.64684015, 0.76827757, 0.64684015, 0.59231722,\n",
      "       0.83023544, 0.90086741, 0.89219331, 0.88228005, 0.84510533,\n",
      "       0.86864932, 0.78066914, 0.81412639, 0.6976456 , 0.81412639,\n",
      "       0.70012392, 0.61462206, 0.75960347, 0.76827757, 0.64684015,\n",
      "       0.76827757, 0.64684015, 0.59231722, 0.83023544, 0.90582404,\n",
      "       0.89219331, 0.91821561, 0.89219331, 0.87112763, 0.78066914,\n",
      "       0.81412639, 0.6976456 , 0.81412639, 0.70012392, 0.61462206,\n",
      "       0.75960347, 0.76827757, 0.64684015, 0.76827757, 0.64684015,\n",
      "       0.59231722, 0.83023544, 0.85130112, 0.78810409, 0.85130112,\n",
      "       0.76951673, 0.74597274, 0.78066914, 0.81412639, 0.6976456 ,\n",
      "       0.81412639, 0.70012392, 0.61462206, 0.75960347, 0.76827757,\n",
      "       0.64684015, 0.76827757, 0.64684015, 0.59231722, 0.83023544,\n",
      "       0.85625774, 0.83271375, 0.85006196, 0.78438662, 0.78314746,\n",
      "       0.78066914, 0.81412639, 0.6976456 , 0.81412639, 0.70012392,\n",
      "       0.61462206, 0.75960347, 0.76827757, 0.64684015, 0.76827757,\n",
      "       0.64684015, 0.59231722, 0.83023544, 0.87856258, 0.85873606,\n",
      "       0.85254027, 0.82651797, 0.84262701, 0.78066914, 0.81412639,\n",
      "       0.6976456 , 0.81412639, 0.70012392, 0.61462206, 0.75960347,\n",
      "       0.76827757, 0.64684015, 0.76827757, 0.64684015, 0.59231722,\n",
      "       0.83023544, 0.89343247, 0.88723668, 0.86369269, 0.8314746 ,\n",
      "       0.85997522, 0.78066914, 0.81412639, 0.6976456 , 0.81412639,\n",
      "       0.70012392, 0.61462206, 0.75960347, 0.76827757, 0.64684015,\n",
      "       0.76827757, 0.64684015, 0.59231722, 0.83023544, 0.90086741,\n",
      "       0.89219331, 0.88228005, 0.84510533, 0.86864932, 0.78066914,\n",
      "       0.81412639, 0.6976456 , 0.81412639, 0.70012392, 0.61462206,\n",
      "       0.75960347, 0.76827757, 0.64684015, 0.76827757, 0.64684015,\n",
      "       0.59231722, 0.83023544, 0.90582404, 0.89219331, 0.91821561,\n",
      "       0.89219331, 0.87112763, 0.78066914, 0.81412639, 0.6976456 ,\n",
      "       0.81412639, 0.70012392, 0.61462206, 0.75960347, 0.76827757,\n",
      "       0.64684015, 0.76827757, 0.64684015, 0.59231722]), 'split5_test_score': array([0.81141439, 0.80645161, 0.7853598 , 0.80024814, 0.77543424,\n",
      "       0.71836228, 0.75310174, 0.77295285, 0.7133995 , 0.78163772,\n",
      "       0.7146402 , 0.63399504, 0.71960298, 0.72704715, 0.62779156,\n",
      "       0.72580645, 0.62903226, 0.59305211, 0.81141439, 0.81637717,\n",
      "       0.82630273, 0.80645161, 0.78411911, 0.7617866 , 0.75310174,\n",
      "       0.77295285, 0.7133995 , 0.78163772, 0.7146402 , 0.63399504,\n",
      "       0.71960298, 0.72704715, 0.62779156, 0.72580645, 0.62903226,\n",
      "       0.59305211, 0.81141439, 0.84243176, 0.84615385, 0.80521092,\n",
      "       0.80272953, 0.82258065, 0.75310174, 0.77295285, 0.7133995 ,\n",
      "       0.78163772, 0.7146402 , 0.63399504, 0.71960298, 0.72704715,\n",
      "       0.62779156, 0.72580645, 0.62903226, 0.59305211, 0.81141439,\n",
      "       0.85856079, 0.87220844, 0.83126551, 0.81637717, 0.84491315,\n",
      "       0.75310174, 0.77295285, 0.7133995 , 0.78163772, 0.7146402 ,\n",
      "       0.63399504, 0.71960298, 0.72704715, 0.62779156, 0.72580645,\n",
      "       0.62903226, 0.59305211, 0.81141439, 0.86724566, 0.87965261,\n",
      "       0.84243176, 0.83002481, 0.85111663, 0.75310174, 0.77295285,\n",
      "       0.7133995 , 0.78163772, 0.7146402 , 0.63399504, 0.71960298,\n",
      "       0.72704715, 0.62779156, 0.72580645, 0.62903226, 0.59305211,\n",
      "       0.81141439, 0.8808933 , 0.87965261, 0.882134  , 0.87220844,\n",
      "       0.85111663, 0.75310174, 0.77295285, 0.7133995 , 0.78163772,\n",
      "       0.7146402 , 0.63399504, 0.71960298, 0.72704715, 0.62779156,\n",
      "       0.72580645, 0.62903226, 0.59305211, 0.81141439, 0.80645161,\n",
      "       0.7853598 , 0.80024814, 0.77543424, 0.71836228, 0.75310174,\n",
      "       0.77295285, 0.7133995 , 0.78163772, 0.7146402 , 0.63399504,\n",
      "       0.71960298, 0.72704715, 0.62779156, 0.72580645, 0.62903226,\n",
      "       0.59305211, 0.81141439, 0.81637717, 0.82630273, 0.80645161,\n",
      "       0.78411911, 0.7617866 , 0.75310174, 0.77295285, 0.7133995 ,\n",
      "       0.78163772, 0.7146402 , 0.63399504, 0.71960298, 0.72704715,\n",
      "       0.62779156, 0.72580645, 0.62903226, 0.59305211, 0.81141439,\n",
      "       0.84243176, 0.84615385, 0.80521092, 0.80272953, 0.82258065,\n",
      "       0.75310174, 0.77295285, 0.7133995 , 0.78163772, 0.7146402 ,\n",
      "       0.63399504, 0.71960298, 0.72704715, 0.62779156, 0.72580645,\n",
      "       0.62903226, 0.59305211, 0.81141439, 0.85856079, 0.87220844,\n",
      "       0.83126551, 0.81637717, 0.84491315, 0.75310174, 0.77295285,\n",
      "       0.7133995 , 0.78163772, 0.7146402 , 0.63399504, 0.71960298,\n",
      "       0.72704715, 0.62779156, 0.72580645, 0.62903226, 0.59305211,\n",
      "       0.81141439, 0.86724566, 0.87965261, 0.84243176, 0.83002481,\n",
      "       0.85111663, 0.75310174, 0.77295285, 0.7133995 , 0.78163772,\n",
      "       0.7146402 , 0.63399504, 0.71960298, 0.72704715, 0.62779156,\n",
      "       0.72580645, 0.62903226, 0.59305211, 0.81141439, 0.8808933 ,\n",
      "       0.87965261, 0.882134  , 0.87220844, 0.85111663, 0.75310174,\n",
      "       0.77295285, 0.7133995 , 0.78163772, 0.7146402 , 0.63399504,\n",
      "       0.71960298, 0.72704715, 0.62779156, 0.72580645, 0.62903226,\n",
      "       0.59305211, 0.81141439, 0.80645161, 0.7853598 , 0.80024814,\n",
      "       0.77543424, 0.71836228, 0.75310174, 0.77295285, 0.7133995 ,\n",
      "       0.78163772, 0.7146402 , 0.63399504, 0.71960298, 0.72704715,\n",
      "       0.62779156, 0.72580645, 0.62903226, 0.59305211, 0.81141439,\n",
      "       0.81637717, 0.82630273, 0.80645161, 0.78411911, 0.7617866 ,\n",
      "       0.75310174, 0.77295285, 0.7133995 , 0.78163772, 0.7146402 ,\n",
      "       0.63399504, 0.71960298, 0.72704715, 0.62779156, 0.72580645,\n",
      "       0.62903226, 0.59305211, 0.81141439, 0.84243176, 0.84615385,\n",
      "       0.80521092, 0.80272953, 0.82258065, 0.75310174, 0.77295285,\n",
      "       0.7133995 , 0.78163772, 0.7146402 , 0.63399504, 0.71960298,\n",
      "       0.72704715, 0.62779156, 0.72580645, 0.62903226, 0.59305211,\n",
      "       0.81141439, 0.85856079, 0.87220844, 0.83126551, 0.81637717,\n",
      "       0.84491315, 0.75310174, 0.77295285, 0.7133995 , 0.78163772,\n",
      "       0.7146402 , 0.63399504, 0.71960298, 0.72704715, 0.62779156,\n",
      "       0.72580645, 0.62903226, 0.59305211, 0.81141439, 0.86724566,\n",
      "       0.87965261, 0.84243176, 0.83002481, 0.85111663, 0.75310174,\n",
      "       0.77295285, 0.7133995 , 0.78163772, 0.7146402 , 0.63399504,\n",
      "       0.71960298, 0.72704715, 0.62779156, 0.72580645, 0.62903226,\n",
      "       0.59305211, 0.81141439, 0.8808933 , 0.87965261, 0.882134  ,\n",
      "       0.87220844, 0.85111663, 0.75310174, 0.77295285, 0.7133995 ,\n",
      "       0.78163772, 0.7146402 , 0.63399504, 0.71960298, 0.72704715,\n",
      "       0.62779156, 0.72580645, 0.62903226, 0.59305211]), 'split6_test_score': array([0.8337469 , 0.84367246, 0.82382134, 0.84491315, 0.80645161,\n",
      "       0.74069479, 0.77171216, 0.81389578, 0.69727047, 0.81389578,\n",
      "       0.70099256, 0.6191067 , 0.75434243, 0.77171216, 0.62903226,\n",
      "       0.77171216, 0.63151365, 0.59801489, 0.8337469 , 0.86600496,\n",
      "       0.86352357, 0.85483871, 0.81141439, 0.79528536, 0.77171216,\n",
      "       0.81389578, 0.69727047, 0.81389578, 0.70099256, 0.6191067 ,\n",
      "       0.75434243, 0.77171216, 0.62903226, 0.77171216, 0.63151365,\n",
      "       0.59801489, 0.8337469 , 0.88957816, 0.90074442, 0.85235732,\n",
      "       0.84987593, 0.86600496, 0.77171216, 0.81389578, 0.69727047,\n",
      "       0.81389578, 0.70099256, 0.6191067 , 0.75434243, 0.77171216,\n",
      "       0.62903226, 0.77171216, 0.63151365, 0.59801489, 0.8337469 ,\n",
      "       0.9044665 , 0.91687345, 0.86228288, 0.86352357, 0.89578164,\n",
      "       0.77171216, 0.81389578, 0.69727047, 0.81389578, 0.70099256,\n",
      "       0.6191067 , 0.75434243, 0.77171216, 0.62903226, 0.77171216,\n",
      "       0.63151365, 0.59801489, 0.8337469 , 0.91935484, 0.91811414,\n",
      "       0.88585608, 0.86476427, 0.90198511, 0.77171216, 0.81389578,\n",
      "       0.69727047, 0.81389578, 0.70099256, 0.6191067 , 0.75434243,\n",
      "       0.77171216, 0.62903226, 0.77171216, 0.63151365, 0.59801489,\n",
      "       0.8337469 , 0.91811414, 0.91811414, 0.91935484, 0.92059553,\n",
      "       0.90198511, 0.77171216, 0.81389578, 0.69727047, 0.81389578,\n",
      "       0.70099256, 0.6191067 , 0.75434243, 0.77171216, 0.62903226,\n",
      "       0.77171216, 0.63151365, 0.59801489, 0.8337469 , 0.84367246,\n",
      "       0.82382134, 0.84491315, 0.80645161, 0.74069479, 0.77171216,\n",
      "       0.81389578, 0.69727047, 0.81389578, 0.70099256, 0.6191067 ,\n",
      "       0.75434243, 0.77171216, 0.62903226, 0.77171216, 0.63151365,\n",
      "       0.59801489, 0.8337469 , 0.86600496, 0.86352357, 0.85483871,\n",
      "       0.81141439, 0.79528536, 0.77171216, 0.81389578, 0.69727047,\n",
      "       0.81389578, 0.70099256, 0.6191067 , 0.75434243, 0.77171216,\n",
      "       0.62903226, 0.77171216, 0.63151365, 0.59801489, 0.8337469 ,\n",
      "       0.88957816, 0.90074442, 0.85235732, 0.84987593, 0.86600496,\n",
      "       0.77171216, 0.81389578, 0.69727047, 0.81389578, 0.70099256,\n",
      "       0.6191067 , 0.75434243, 0.77171216, 0.62903226, 0.77171216,\n",
      "       0.63151365, 0.59801489, 0.8337469 , 0.9044665 , 0.91687345,\n",
      "       0.86228288, 0.86352357, 0.89578164, 0.77171216, 0.81389578,\n",
      "       0.69727047, 0.81389578, 0.70099256, 0.6191067 , 0.75434243,\n",
      "       0.77171216, 0.62903226, 0.77171216, 0.63151365, 0.59801489,\n",
      "       0.8337469 , 0.91935484, 0.91811414, 0.88585608, 0.86476427,\n",
      "       0.90198511, 0.77171216, 0.81389578, 0.69727047, 0.81389578,\n",
      "       0.70099256, 0.6191067 , 0.75434243, 0.77171216, 0.62903226,\n",
      "       0.77171216, 0.63151365, 0.59801489, 0.8337469 , 0.91811414,\n",
      "       0.91811414, 0.91935484, 0.92059553, 0.90198511, 0.77171216,\n",
      "       0.81389578, 0.69727047, 0.81389578, 0.70099256, 0.6191067 ,\n",
      "       0.75434243, 0.77171216, 0.62903226, 0.77171216, 0.63151365,\n",
      "       0.59801489, 0.8337469 , 0.84367246, 0.82382134, 0.84491315,\n",
      "       0.80645161, 0.74069479, 0.77171216, 0.81389578, 0.69727047,\n",
      "       0.81389578, 0.70099256, 0.6191067 , 0.75434243, 0.77171216,\n",
      "       0.62903226, 0.77171216, 0.63151365, 0.59801489, 0.8337469 ,\n",
      "       0.86600496, 0.86352357, 0.85483871, 0.81141439, 0.79528536,\n",
      "       0.77171216, 0.81389578, 0.69727047, 0.81389578, 0.70099256,\n",
      "       0.6191067 , 0.75434243, 0.77171216, 0.62903226, 0.77171216,\n",
      "       0.63151365, 0.59801489, 0.8337469 , 0.88957816, 0.90074442,\n",
      "       0.85235732, 0.84987593, 0.86600496, 0.77171216, 0.81389578,\n",
      "       0.69727047, 0.81389578, 0.70099256, 0.6191067 , 0.75434243,\n",
      "       0.77171216, 0.62903226, 0.77171216, 0.63151365, 0.59801489,\n",
      "       0.8337469 , 0.9044665 , 0.91687345, 0.86228288, 0.86352357,\n",
      "       0.89578164, 0.77171216, 0.81389578, 0.69727047, 0.81389578,\n",
      "       0.70099256, 0.6191067 , 0.75434243, 0.77171216, 0.62903226,\n",
      "       0.77171216, 0.63151365, 0.59801489, 0.8337469 , 0.91935484,\n",
      "       0.91811414, 0.88585608, 0.86476427, 0.90198511, 0.77171216,\n",
      "       0.81389578, 0.69727047, 0.81389578, 0.70099256, 0.6191067 ,\n",
      "       0.75434243, 0.77171216, 0.62903226, 0.77171216, 0.63151365,\n",
      "       0.59801489, 0.8337469 , 0.91811414, 0.91811414, 0.91935484,\n",
      "       0.92059553, 0.90198511, 0.77171216, 0.81389578, 0.69727047,\n",
      "       0.81389578, 0.70099256, 0.6191067 , 0.75434243, 0.77171216,\n",
      "       0.62903226, 0.77171216, 0.63151365, 0.59801489]), 'split7_test_score': array([0.83995037, 0.84863524, 0.82630273, 0.84863524, 0.79156328,\n",
      "       0.74069479, 0.78411911, 0.81637717, 0.71836228, 0.81885856,\n",
      "       0.71960298, 0.6191067 , 0.76054591, 0.77543424, 0.64019851,\n",
      "       0.77667494, 0.6439206 , 0.59677419, 0.83995037, 0.87220844,\n",
      "       0.86104218, 0.85856079, 0.80521092, 0.77915633, 0.78411911,\n",
      "       0.81637717, 0.71836228, 0.81885856, 0.71960298, 0.6191067 ,\n",
      "       0.76054591, 0.77543424, 0.64019851, 0.77667494, 0.6439206 ,\n",
      "       0.59677419, 0.83995037, 0.89330025, 0.89454094, 0.86104218,\n",
      "       0.8325062 , 0.86352357, 0.78411911, 0.81637717, 0.71836228,\n",
      "       0.81885856, 0.71960298, 0.6191067 , 0.76054591, 0.77543424,\n",
      "       0.64019851, 0.77667494, 0.6439206 , 0.59677419, 0.83995037,\n",
      "       0.91066998, 0.91439206, 0.87841191, 0.85111663, 0.89205955,\n",
      "       0.78411911, 0.81637717, 0.71836228, 0.81885856, 0.71960298,\n",
      "       0.6191067 , 0.76054591, 0.77543424, 0.64019851, 0.77667494,\n",
      "       0.6439206 , 0.59677419, 0.83995037, 0.92183623, 0.91315136,\n",
      "       0.88957816, 0.86600496, 0.89578164, 0.78411911, 0.81637717,\n",
      "       0.71836228, 0.81885856, 0.71960298, 0.6191067 , 0.76054591,\n",
      "       0.77543424, 0.64019851, 0.77667494, 0.6439206 , 0.59677419,\n",
      "       0.83995037, 0.92555831, 0.91315136, 0.92679901, 0.91315136,\n",
      "       0.89702233, 0.78411911, 0.81637717, 0.71836228, 0.81885856,\n",
      "       0.71960298, 0.6191067 , 0.76054591, 0.77543424, 0.64019851,\n",
      "       0.77667494, 0.6439206 , 0.59677419, 0.83995037, 0.84863524,\n",
      "       0.82630273, 0.84863524, 0.79156328, 0.74069479, 0.78411911,\n",
      "       0.81637717, 0.71836228, 0.81885856, 0.71960298, 0.6191067 ,\n",
      "       0.76054591, 0.77543424, 0.64019851, 0.77667494, 0.6439206 ,\n",
      "       0.59677419, 0.83995037, 0.87220844, 0.86104218, 0.85856079,\n",
      "       0.80521092, 0.77915633, 0.78411911, 0.81637717, 0.71836228,\n",
      "       0.81885856, 0.71960298, 0.6191067 , 0.76054591, 0.77543424,\n",
      "       0.64019851, 0.77667494, 0.6439206 , 0.59677419, 0.83995037,\n",
      "       0.89330025, 0.89454094, 0.86104218, 0.8325062 , 0.86352357,\n",
      "       0.78411911, 0.81637717, 0.71836228, 0.81885856, 0.71960298,\n",
      "       0.6191067 , 0.76054591, 0.77543424, 0.64019851, 0.77667494,\n",
      "       0.6439206 , 0.59677419, 0.83995037, 0.91066998, 0.91439206,\n",
      "       0.87841191, 0.85111663, 0.89205955, 0.78411911, 0.81637717,\n",
      "       0.71836228, 0.81885856, 0.71960298, 0.6191067 , 0.76054591,\n",
      "       0.77543424, 0.64019851, 0.77667494, 0.6439206 , 0.59677419,\n",
      "       0.83995037, 0.92183623, 0.91315136, 0.88957816, 0.86600496,\n",
      "       0.89578164, 0.78411911, 0.81637717, 0.71836228, 0.81885856,\n",
      "       0.71960298, 0.6191067 , 0.76054591, 0.77543424, 0.64019851,\n",
      "       0.77667494, 0.6439206 , 0.59677419, 0.83995037, 0.92555831,\n",
      "       0.91315136, 0.92679901, 0.91315136, 0.89702233, 0.78411911,\n",
      "       0.81637717, 0.71836228, 0.81885856, 0.71960298, 0.6191067 ,\n",
      "       0.76054591, 0.77543424, 0.64019851, 0.77667494, 0.6439206 ,\n",
      "       0.59677419, 0.83995037, 0.84863524, 0.82630273, 0.84863524,\n",
      "       0.79156328, 0.74069479, 0.78411911, 0.81637717, 0.71836228,\n",
      "       0.81885856, 0.71960298, 0.6191067 , 0.76054591, 0.77543424,\n",
      "       0.64019851, 0.77667494, 0.6439206 , 0.59677419, 0.83995037,\n",
      "       0.87220844, 0.86104218, 0.85856079, 0.80521092, 0.77915633,\n",
      "       0.78411911, 0.81637717, 0.71836228, 0.81885856, 0.71960298,\n",
      "       0.6191067 , 0.76054591, 0.77543424, 0.64019851, 0.77667494,\n",
      "       0.6439206 , 0.59677419, 0.83995037, 0.89330025, 0.89454094,\n",
      "       0.86104218, 0.8325062 , 0.86352357, 0.78411911, 0.81637717,\n",
      "       0.71836228, 0.81885856, 0.71960298, 0.6191067 , 0.76054591,\n",
      "       0.77543424, 0.64019851, 0.77667494, 0.6439206 , 0.59677419,\n",
      "       0.83995037, 0.91066998, 0.91439206, 0.87841191, 0.85111663,\n",
      "       0.89205955, 0.78411911, 0.81637717, 0.71836228, 0.81885856,\n",
      "       0.71960298, 0.6191067 , 0.76054591, 0.77543424, 0.64019851,\n",
      "       0.77667494, 0.6439206 , 0.59677419, 0.83995037, 0.92183623,\n",
      "       0.91315136, 0.88957816, 0.86600496, 0.89578164, 0.78411911,\n",
      "       0.81637717, 0.71836228, 0.81885856, 0.71960298, 0.6191067 ,\n",
      "       0.76054591, 0.77543424, 0.64019851, 0.77667494, 0.6439206 ,\n",
      "       0.59677419, 0.83995037, 0.92555831, 0.91315136, 0.92679901,\n",
      "       0.91315136, 0.89702233, 0.78411911, 0.81637717, 0.71836228,\n",
      "       0.81885856, 0.71960298, 0.6191067 , 0.76054591, 0.77543424,\n",
      "       0.64019851, 0.77667494, 0.6439206 , 0.59677419]), 'split8_test_score': array([0.81885856, 0.84367246, 0.80645161, 0.83870968, 0.77047146,\n",
      "       0.75186104, 0.78411911, 0.80769231, 0.71960298, 0.808933  ,\n",
      "       0.72456576, 0.60918114, 0.75682382, 0.75806452, 0.65136476,\n",
      "       0.75806452, 0.64888337, 0.59305211, 0.81885856, 0.87344913,\n",
      "       0.85856079, 0.85359801, 0.77791563, 0.80272953, 0.78411911,\n",
      "       0.80769231, 0.71960298, 0.808933  , 0.72456576, 0.60918114,\n",
      "       0.75682382, 0.75806452, 0.65136476, 0.75806452, 0.64888337,\n",
      "       0.59305211, 0.81885856, 0.87965261, 0.87965261, 0.85483871,\n",
      "       0.82009926, 0.86848635, 0.78411911, 0.80769231, 0.71960298,\n",
      "       0.808933  , 0.72456576, 0.60918114, 0.75682382, 0.75806452,\n",
      "       0.65136476, 0.75806452, 0.64888337, 0.59305211, 0.81885856,\n",
      "       0.89205955, 0.89330025, 0.87468983, 0.85359801, 0.89205955,\n",
      "       0.78411911, 0.80769231, 0.71960298, 0.808933  , 0.72456576,\n",
      "       0.60918114, 0.75682382, 0.75806452, 0.65136476, 0.75806452,\n",
      "       0.64888337, 0.59305211, 0.81885856, 0.9044665 , 0.89702233,\n",
      "       0.87965261, 0.86352357, 0.90322581, 0.78411911, 0.80769231,\n",
      "       0.71960298, 0.808933  , 0.72456576, 0.60918114, 0.75682382,\n",
      "       0.75806452, 0.65136476, 0.75806452, 0.64888337, 0.59305211,\n",
      "       0.81885856, 0.91563275, 0.89702233, 0.92555831, 0.89454094,\n",
      "       0.90322581, 0.78411911, 0.80769231, 0.71960298, 0.808933  ,\n",
      "       0.72456576, 0.60918114, 0.75682382, 0.75806452, 0.65136476,\n",
      "       0.75806452, 0.64888337, 0.59305211, 0.81885856, 0.84367246,\n",
      "       0.80645161, 0.83870968, 0.77047146, 0.75186104, 0.78411911,\n",
      "       0.80769231, 0.71960298, 0.808933  , 0.72456576, 0.60918114,\n",
      "       0.75682382, 0.75806452, 0.65136476, 0.75806452, 0.64888337,\n",
      "       0.59305211, 0.81885856, 0.87344913, 0.85856079, 0.85359801,\n",
      "       0.77791563, 0.80272953, 0.78411911, 0.80769231, 0.71960298,\n",
      "       0.808933  , 0.72456576, 0.60918114, 0.75682382, 0.75806452,\n",
      "       0.65136476, 0.75806452, 0.64888337, 0.59305211, 0.81885856,\n",
      "       0.87965261, 0.87965261, 0.85483871, 0.82009926, 0.86848635,\n",
      "       0.78411911, 0.80769231, 0.71960298, 0.808933  , 0.72456576,\n",
      "       0.60918114, 0.75682382, 0.75806452, 0.65136476, 0.75806452,\n",
      "       0.64888337, 0.59305211, 0.81885856, 0.89205955, 0.89330025,\n",
      "       0.87468983, 0.85359801, 0.89205955, 0.78411911, 0.80769231,\n",
      "       0.71960298, 0.808933  , 0.72456576, 0.60918114, 0.75682382,\n",
      "       0.75806452, 0.65136476, 0.75806452, 0.64888337, 0.59305211,\n",
      "       0.81885856, 0.9044665 , 0.89702233, 0.87965261, 0.86352357,\n",
      "       0.90322581, 0.78411911, 0.80769231, 0.71960298, 0.808933  ,\n",
      "       0.72456576, 0.60918114, 0.75682382, 0.75806452, 0.65136476,\n",
      "       0.75806452, 0.64888337, 0.59305211, 0.81885856, 0.91563275,\n",
      "       0.89702233, 0.92555831, 0.89454094, 0.90322581, 0.78411911,\n",
      "       0.80769231, 0.71960298, 0.808933  , 0.72456576, 0.60918114,\n",
      "       0.75682382, 0.75806452, 0.65136476, 0.75806452, 0.64888337,\n",
      "       0.59305211, 0.81885856, 0.84367246, 0.80645161, 0.83870968,\n",
      "       0.77047146, 0.75186104, 0.78411911, 0.80769231, 0.71960298,\n",
      "       0.808933  , 0.72456576, 0.60918114, 0.75682382, 0.75806452,\n",
      "       0.65136476, 0.75806452, 0.64888337, 0.59305211, 0.81885856,\n",
      "       0.87344913, 0.85856079, 0.85359801, 0.77791563, 0.80272953,\n",
      "       0.78411911, 0.80769231, 0.71960298, 0.808933  , 0.72456576,\n",
      "       0.60918114, 0.75682382, 0.75806452, 0.65136476, 0.75806452,\n",
      "       0.64888337, 0.59305211, 0.81885856, 0.87965261, 0.87965261,\n",
      "       0.85483871, 0.82009926, 0.86848635, 0.78411911, 0.80769231,\n",
      "       0.71960298, 0.808933  , 0.72456576, 0.60918114, 0.75682382,\n",
      "       0.75806452, 0.65136476, 0.75806452, 0.64888337, 0.59305211,\n",
      "       0.81885856, 0.89205955, 0.89330025, 0.87468983, 0.85359801,\n",
      "       0.89205955, 0.78411911, 0.80769231, 0.71960298, 0.808933  ,\n",
      "       0.72456576, 0.60918114, 0.75682382, 0.75806452, 0.65136476,\n",
      "       0.75806452, 0.64888337, 0.59305211, 0.81885856, 0.9044665 ,\n",
      "       0.89702233, 0.87965261, 0.86352357, 0.90322581, 0.78411911,\n",
      "       0.80769231, 0.71960298, 0.808933  , 0.72456576, 0.60918114,\n",
      "       0.75682382, 0.75806452, 0.65136476, 0.75806452, 0.64888337,\n",
      "       0.59305211, 0.81885856, 0.91563275, 0.89702233, 0.92555831,\n",
      "       0.89454094, 0.90322581, 0.78411911, 0.80769231, 0.71960298,\n",
      "       0.808933  , 0.72456576, 0.60918114, 0.75682382, 0.75806452,\n",
      "       0.65136476, 0.75806452, 0.64888337, 0.59305211]), 'split9_test_score': array([0.81141439, 0.83126551, 0.78287841, 0.82133995, 0.76923077,\n",
      "       0.7146402 , 0.75682382, 0.80272953, 0.70471464, 0.80397022,\n",
      "       0.70595533, 0.61042184, 0.72952854, 0.74317618, 0.63647643,\n",
      "       0.74689826, 0.63771712, 0.59181141, 0.81141439, 0.83870968,\n",
      "       0.8325062 , 0.82258065, 0.77419355, 0.76550868, 0.75682382,\n",
      "       0.80272953, 0.70471464, 0.80397022, 0.70595533, 0.61042184,\n",
      "       0.72952854, 0.74317618, 0.63647643, 0.74689826, 0.63771712,\n",
      "       0.59181141, 0.81141439, 0.86228288, 0.86228288, 0.82506203,\n",
      "       0.79900744, 0.85111663, 0.75682382, 0.80272953, 0.70471464,\n",
      "       0.80397022, 0.70595533, 0.61042184, 0.72952854, 0.74317618,\n",
      "       0.63647643, 0.74689826, 0.63771712, 0.59181141, 0.81141439,\n",
      "       0.87220844, 0.87965261, 0.83746898, 0.83002481, 0.87344913,\n",
      "       0.75682382, 0.80272953, 0.70471464, 0.80397022, 0.70595533,\n",
      "       0.61042184, 0.72952854, 0.74317618, 0.63647643, 0.74689826,\n",
      "       0.63771712, 0.59181141, 0.81141439, 0.88585608, 0.88833747,\n",
      "       0.85111663, 0.84367246, 0.87965261, 0.75682382, 0.80272953,\n",
      "       0.70471464, 0.80397022, 0.70595533, 0.61042184, 0.72952854,\n",
      "       0.74317618, 0.63647643, 0.74689826, 0.63771712, 0.59181141,\n",
      "       0.81141439, 0.89205955, 0.88833747, 0.89950372, 0.89081886,\n",
      "       0.87965261, 0.75682382, 0.80272953, 0.70471464, 0.80397022,\n",
      "       0.70595533, 0.61042184, 0.72952854, 0.74317618, 0.63647643,\n",
      "       0.74689826, 0.63771712, 0.59181141, 0.81141439, 0.83126551,\n",
      "       0.78287841, 0.82133995, 0.76923077, 0.7146402 , 0.75682382,\n",
      "       0.80272953, 0.70471464, 0.80397022, 0.70595533, 0.61042184,\n",
      "       0.72952854, 0.74317618, 0.63647643, 0.74689826, 0.63771712,\n",
      "       0.59181141, 0.81141439, 0.83870968, 0.8325062 , 0.82258065,\n",
      "       0.77419355, 0.76550868, 0.75682382, 0.80272953, 0.70471464,\n",
      "       0.80397022, 0.70595533, 0.61042184, 0.72952854, 0.74317618,\n",
      "       0.63647643, 0.74689826, 0.63771712, 0.59181141, 0.81141439,\n",
      "       0.86228288, 0.86228288, 0.82506203, 0.79900744, 0.85111663,\n",
      "       0.75682382, 0.80272953, 0.70471464, 0.80397022, 0.70595533,\n",
      "       0.61042184, 0.72952854, 0.74317618, 0.63647643, 0.74689826,\n",
      "       0.63771712, 0.59181141, 0.81141439, 0.87220844, 0.87965261,\n",
      "       0.83746898, 0.83002481, 0.87344913, 0.75682382, 0.80272953,\n",
      "       0.70471464, 0.80397022, 0.70595533, 0.61042184, 0.72952854,\n",
      "       0.74317618, 0.63647643, 0.74689826, 0.63771712, 0.59181141,\n",
      "       0.81141439, 0.88585608, 0.88833747, 0.85111663, 0.84367246,\n",
      "       0.87965261, 0.75682382, 0.80272953, 0.70471464, 0.80397022,\n",
      "       0.70595533, 0.61042184, 0.72952854, 0.74317618, 0.63647643,\n",
      "       0.74689826, 0.63771712, 0.59181141, 0.81141439, 0.89205955,\n",
      "       0.88833747, 0.89950372, 0.89081886, 0.87965261, 0.75682382,\n",
      "       0.80272953, 0.70471464, 0.80397022, 0.70595533, 0.61042184,\n",
      "       0.72952854, 0.74317618, 0.63647643, 0.74689826, 0.63771712,\n",
      "       0.59181141, 0.81141439, 0.83126551, 0.78287841, 0.82133995,\n",
      "       0.76923077, 0.7146402 , 0.75682382, 0.80272953, 0.70471464,\n",
      "       0.80397022, 0.70595533, 0.61042184, 0.72952854, 0.74317618,\n",
      "       0.63647643, 0.74689826, 0.63771712, 0.59181141, 0.81141439,\n",
      "       0.83870968, 0.8325062 , 0.82258065, 0.77419355, 0.76550868,\n",
      "       0.75682382, 0.80272953, 0.70471464, 0.80397022, 0.70595533,\n",
      "       0.61042184, 0.72952854, 0.74317618, 0.63647643, 0.74689826,\n",
      "       0.63771712, 0.59181141, 0.81141439, 0.86228288, 0.86228288,\n",
      "       0.82506203, 0.79900744, 0.85111663, 0.75682382, 0.80272953,\n",
      "       0.70471464, 0.80397022, 0.70595533, 0.61042184, 0.72952854,\n",
      "       0.74317618, 0.63647643, 0.74689826, 0.63771712, 0.59181141,\n",
      "       0.81141439, 0.87220844, 0.87965261, 0.83746898, 0.83002481,\n",
      "       0.87344913, 0.75682382, 0.80272953, 0.70471464, 0.80397022,\n",
      "       0.70595533, 0.61042184, 0.72952854, 0.74317618, 0.63647643,\n",
      "       0.74689826, 0.63771712, 0.59181141, 0.81141439, 0.88585608,\n",
      "       0.88833747, 0.85111663, 0.84367246, 0.87965261, 0.75682382,\n",
      "       0.80272953, 0.70471464, 0.80397022, 0.70595533, 0.61042184,\n",
      "       0.72952854, 0.74317618, 0.63647643, 0.74689826, 0.63771712,\n",
      "       0.59181141, 0.81141439, 0.89205955, 0.88833747, 0.89950372,\n",
      "       0.89081886, 0.87965261, 0.75682382, 0.80272953, 0.70471464,\n",
      "       0.80397022, 0.70595533, 0.61042184, 0.72952854, 0.74317618,\n",
      "       0.63647643, 0.74689826, 0.63771712, 0.59181141]), 'mean_test_score': array([0.82454961, 0.836081  , 0.80124223, 0.83161758, 0.77991489,\n",
      "       0.7373812 , 0.77024162, 0.79975386, 0.70762743, 0.80149037,\n",
      "       0.71097469, 0.62095314, 0.74655773, 0.75883215, 0.64079119,\n",
      "       0.75833695, 0.64141153, 0.5975183 , 0.82454961, 0.85319291,\n",
      "       0.84414398, 0.83806642, 0.79119614, 0.78177255, 0.77024162,\n",
      "       0.79975386, 0.70762743, 0.80149037, 0.71097469, 0.62095314,\n",
      "       0.74655773, 0.75883215, 0.64079119, 0.75833695, 0.64141153,\n",
      "       0.5975183 , 0.82454961, 0.87228838, 0.87315779, 0.8394298 ,\n",
      "       0.8195916 , 0.85455659, 0.77024162, 0.79975386, 0.70762743,\n",
      "       0.80149037, 0.71097469, 0.62095314, 0.74655773, 0.75883215,\n",
      "       0.64079119, 0.75833695, 0.64141153, 0.5975183 , 0.82454961,\n",
      "       0.88617571, 0.89386325, 0.85542554, 0.83992746, 0.87947934,\n",
      "       0.77024162, 0.79975386, 0.70762743, 0.80149037, 0.71097469,\n",
      "       0.62095314, 0.74655773, 0.75883215, 0.64079119, 0.75833695,\n",
      "       0.64141153, 0.5975183 , 0.82454961, 0.89832698, 0.89807884,\n",
      "       0.86955993, 0.850343  , 0.88543145, 0.77024162, 0.79975386,\n",
      "       0.70762743, 0.80149037, 0.71097469, 0.62095314, 0.74655773,\n",
      "       0.75883215, 0.64079119, 0.75833695, 0.64141153, 0.5975183 ,\n",
      "       0.82454961, 0.90650957, 0.89807884, 0.91307972, 0.89807823,\n",
      "       0.88605118, 0.77024162, 0.79975386, 0.70762743, 0.80149037,\n",
      "       0.71097469, 0.62095314, 0.74655773, 0.75883215, 0.64079119,\n",
      "       0.75833695, 0.64141153, 0.5975183 , 0.82454961, 0.836081  ,\n",
      "       0.80124223, 0.83161758, 0.77991489, 0.7373812 , 0.77024162,\n",
      "       0.79975386, 0.70762743, 0.80149037, 0.71097469, 0.62095314,\n",
      "       0.74655773, 0.75883215, 0.64079119, 0.75833695, 0.64141153,\n",
      "       0.5975183 , 0.82454961, 0.85319291, 0.84414398, 0.83806642,\n",
      "       0.79119614, 0.78177255, 0.77024162, 0.79975386, 0.70762743,\n",
      "       0.80149037, 0.71097469, 0.62095314, 0.74655773, 0.75883215,\n",
      "       0.64079119, 0.75833695, 0.64141153, 0.5975183 , 0.82454961,\n",
      "       0.87228838, 0.87315779, 0.8394298 , 0.8195916 , 0.85455659,\n",
      "       0.77024162, 0.79975386, 0.70762743, 0.80149037, 0.71097469,\n",
      "       0.62095314, 0.74655773, 0.75883215, 0.64079119, 0.75833695,\n",
      "       0.64141153, 0.5975183 , 0.82454961, 0.88617571, 0.89386325,\n",
      "       0.85542554, 0.83992746, 0.87947934, 0.77024162, 0.79975386,\n",
      "       0.70762743, 0.80149037, 0.71097469, 0.62095314, 0.74655773,\n",
      "       0.75883215, 0.64079119, 0.75833695, 0.64141153, 0.5975183 ,\n",
      "       0.82454961, 0.89832698, 0.89807884, 0.86955993, 0.850343  ,\n",
      "       0.88543145, 0.77024162, 0.79975386, 0.70762743, 0.80149037,\n",
      "       0.71097469, 0.62095314, 0.74655773, 0.75883215, 0.64079119,\n",
      "       0.75833695, 0.64141153, 0.5975183 , 0.82454961, 0.90650957,\n",
      "       0.89807884, 0.91307972, 0.89807823, 0.88605118, 0.77024162,\n",
      "       0.79975386, 0.70762743, 0.80149037, 0.71097469, 0.62095314,\n",
      "       0.74655773, 0.75883215, 0.64079119, 0.75833695, 0.64141153,\n",
      "       0.5975183 , 0.82454961, 0.836081  , 0.80124223, 0.83161758,\n",
      "       0.77991489, 0.7373812 , 0.77024162, 0.79975386, 0.70762743,\n",
      "       0.80149037, 0.71097469, 0.62095314, 0.74655773, 0.75883215,\n",
      "       0.64079119, 0.75833695, 0.64141153, 0.5975183 , 0.82454961,\n",
      "       0.85319291, 0.84414398, 0.83806642, 0.79119614, 0.78177255,\n",
      "       0.77024162, 0.79975386, 0.70762743, 0.80149037, 0.71097469,\n",
      "       0.62095314, 0.74655773, 0.75883215, 0.64079119, 0.75833695,\n",
      "       0.64141153, 0.5975183 , 0.82454961, 0.87228838, 0.87315779,\n",
      "       0.8394298 , 0.8195916 , 0.85455659, 0.77024162, 0.79975386,\n",
      "       0.70762743, 0.80149037, 0.71097469, 0.62095314, 0.74655773,\n",
      "       0.75883215, 0.64079119, 0.75833695, 0.64141153, 0.5975183 ,\n",
      "       0.82454961, 0.88617571, 0.89386325, 0.85542554, 0.83992746,\n",
      "       0.87947934, 0.77024162, 0.79975386, 0.70762743, 0.80149037,\n",
      "       0.71097469, 0.62095314, 0.74655773, 0.75883215, 0.64079119,\n",
      "       0.75833695, 0.64141153, 0.5975183 , 0.82454961, 0.89832698,\n",
      "       0.89807884, 0.86955993, 0.850343  , 0.88543145, 0.77024162,\n",
      "       0.79975386, 0.70762743, 0.80149037, 0.71097469, 0.62095314,\n",
      "       0.74655773, 0.75883215, 0.64079119, 0.75833695, 0.64141153,\n",
      "       0.5975183 , 0.82454961, 0.90650957, 0.89807884, 0.91307972,\n",
      "       0.89807823, 0.88605118, 0.77024162, 0.79975386, 0.70762743,\n",
      "       0.80149037, 0.71097469, 0.62095314, 0.74655773, 0.75883215,\n",
      "       0.64079119, 0.75833695, 0.64141153, 0.5975183 ]), 'std_test_score': array([0.01166148, 0.01249769, 0.01464549, 0.01448952, 0.01189381,\n",
      "       0.01320716, 0.01101283, 0.01343579, 0.01044772, 0.01188505,\n",
      "       0.00958453, 0.00950482, 0.01335387, 0.01424965, 0.01160811,\n",
      "       0.01416323, 0.01056599, 0.00534101, 0.01166148, 0.0158989 ,\n",
      "       0.0140787 , 0.01598641, 0.01152584, 0.01222637, 0.01101283,\n",
      "       0.01343579, 0.01044772, 0.01188505, 0.00958453, 0.00950482,\n",
      "       0.01335387, 0.01424965, 0.01160811, 0.01416323, 0.01056599,\n",
      "       0.00534101, 0.01166148, 0.01380782, 0.01590695, 0.01601205,\n",
      "       0.0141692 , 0.01374639, 0.01101283, 0.01343579, 0.01044772,\n",
      "       0.01188505, 0.00958453, 0.00950482, 0.01335387, 0.01424965,\n",
      "       0.01160811, 0.01416323, 0.01056599, 0.00534101, 0.01166148,\n",
      "       0.0142873 , 0.01437514, 0.01415954, 0.01393937, 0.01670943,\n",
      "       0.01101283, 0.01343579, 0.01044772, 0.01188505, 0.00958453,\n",
      "       0.00950482, 0.01335387, 0.01424965, 0.01160811, 0.01416323,\n",
      "       0.01056599, 0.00534101, 0.01166148, 0.01491258, 0.01149363,\n",
      "       0.01453757, 0.01364123, 0.0163484 , 0.01101283, 0.01343579,\n",
      "       0.01044772, 0.01188505, 0.00958453, 0.00950482, 0.01335387,\n",
      "       0.01424965, 0.01160811, 0.01416323, 0.01056599, 0.00534101,\n",
      "       0.01166148, 0.01229675, 0.01149363, 0.01282412, 0.01313619,\n",
      "       0.01621108, 0.01101283, 0.01343579, 0.01044772, 0.01188505,\n",
      "       0.00958453, 0.00950482, 0.01335387, 0.01424965, 0.01160811,\n",
      "       0.01416323, 0.01056599, 0.00534101, 0.01166148, 0.01249769,\n",
      "       0.01464549, 0.01448952, 0.01189381, 0.01320716, 0.01101283,\n",
      "       0.01343579, 0.01044772, 0.01188505, 0.00958453, 0.00950482,\n",
      "       0.01335387, 0.01424965, 0.01160811, 0.01416323, 0.01056599,\n",
      "       0.00534101, 0.01166148, 0.0158989 , 0.0140787 , 0.01598641,\n",
      "       0.01152584, 0.01222637, 0.01101283, 0.01343579, 0.01044772,\n",
      "       0.01188505, 0.00958453, 0.00950482, 0.01335387, 0.01424965,\n",
      "       0.01160811, 0.01416323, 0.01056599, 0.00534101, 0.01166148,\n",
      "       0.01380782, 0.01590695, 0.01601205, 0.0141692 , 0.01374639,\n",
      "       0.01101283, 0.01343579, 0.01044772, 0.01188505, 0.00958453,\n",
      "       0.00950482, 0.01335387, 0.01424965, 0.01160811, 0.01416323,\n",
      "       0.01056599, 0.00534101, 0.01166148, 0.0142873 , 0.01437514,\n",
      "       0.01415954, 0.01393937, 0.01670943, 0.01101283, 0.01343579,\n",
      "       0.01044772, 0.01188505, 0.00958453, 0.00950482, 0.01335387,\n",
      "       0.01424965, 0.01160811, 0.01416323, 0.01056599, 0.00534101,\n",
      "       0.01166148, 0.01491258, 0.01149363, 0.01453757, 0.01364123,\n",
      "       0.0163484 , 0.01101283, 0.01343579, 0.01044772, 0.01188505,\n",
      "       0.00958453, 0.00950482, 0.01335387, 0.01424965, 0.01160811,\n",
      "       0.01416323, 0.01056599, 0.00534101, 0.01166148, 0.01229675,\n",
      "       0.01149363, 0.01282412, 0.01313619, 0.01621108, 0.01101283,\n",
      "       0.01343579, 0.01044772, 0.01188505, 0.00958453, 0.00950482,\n",
      "       0.01335387, 0.01424965, 0.01160811, 0.01416323, 0.01056599,\n",
      "       0.00534101, 0.01166148, 0.01249769, 0.01464549, 0.01448952,\n",
      "       0.01189381, 0.01320716, 0.01101283, 0.01343579, 0.01044772,\n",
      "       0.01188505, 0.00958453, 0.00950482, 0.01335387, 0.01424965,\n",
      "       0.01160811, 0.01416323, 0.01056599, 0.00534101, 0.01166148,\n",
      "       0.0158989 , 0.0140787 , 0.01598641, 0.01152584, 0.01222637,\n",
      "       0.01101283, 0.01343579, 0.01044772, 0.01188505, 0.00958453,\n",
      "       0.00950482, 0.01335387, 0.01424965, 0.01160811, 0.01416323,\n",
      "       0.01056599, 0.00534101, 0.01166148, 0.01380782, 0.01590695,\n",
      "       0.01601205, 0.0141692 , 0.01374639, 0.01101283, 0.01343579,\n",
      "       0.01044772, 0.01188505, 0.00958453, 0.00950482, 0.01335387,\n",
      "       0.01424965, 0.01160811, 0.01416323, 0.01056599, 0.00534101,\n",
      "       0.01166148, 0.0142873 , 0.01437514, 0.01415954, 0.01393937,\n",
      "       0.01670943, 0.01101283, 0.01343579, 0.01044772, 0.01188505,\n",
      "       0.00958453, 0.00950482, 0.01335387, 0.01424965, 0.01160811,\n",
      "       0.01416323, 0.01056599, 0.00534101, 0.01166148, 0.01491258,\n",
      "       0.01149363, 0.01453757, 0.01364123, 0.0163484 , 0.01101283,\n",
      "       0.01343579, 0.01044772, 0.01188505, 0.00958453, 0.00950482,\n",
      "       0.01335387, 0.01424965, 0.01160811, 0.01416323, 0.01056599,\n",
      "       0.00534101, 0.01166148, 0.01229675, 0.01149363, 0.01282412,\n",
      "       0.01313619, 0.01621108, 0.01101283, 0.01343579, 0.01044772,\n",
      "       0.01188505, 0.00958453, 0.00950482, 0.01335387, 0.01424965,\n",
      "       0.01160811, 0.01416323, 0.01056599, 0.00534101]), 'rank_test_score': array([ 73,  67, 112,  70, 139, 214, 142, 115, 235,  94, 217, 289, 196,\n",
      "       160, 271, 178, 253, 307,  73,  49,  55,  64, 133, 136, 142, 115,\n",
      "       235,  94, 217, 289, 196, 160, 271, 178, 253, 307,  73,  37,  34,\n",
      "        61,  91,  46, 142, 115, 235,  94, 217, 289, 196, 160, 271, 178,\n",
      "       253, 307,  73,  22,  19,  43,  58,  31, 142, 115, 235,  94, 217,\n",
      "       289, 196, 160, 271, 178, 253, 307,  73,   7,  10,  40,  52,  28,\n",
      "       142, 115, 235,  94, 217, 289, 196, 160, 271, 178, 253, 307,  73,\n",
      "         4,  10,   1,  16,  25, 142, 115, 235,  94, 217, 289, 196, 160,\n",
      "       271, 178, 253, 307,  73,  67, 112,  70, 139, 214, 142, 115, 235,\n",
      "        94, 217, 289, 196, 160, 271, 178, 253, 307,  73,  49,  55,  64,\n",
      "       133, 136, 142, 115, 235,  94, 217, 289, 196, 160, 271, 178, 253,\n",
      "       307,  73,  37,  34,  61,  91,  46, 142, 115, 235,  94, 217, 289,\n",
      "       196, 160, 271, 178, 253, 307,  73,  22,  19,  43,  58,  31, 142,\n",
      "       115, 235,  94, 217, 289, 196, 160, 271, 178, 253, 307,  73,   7,\n",
      "        10,  40,  52,  28, 142, 115, 235,  94, 217, 289, 196, 160, 271,\n",
      "       178, 253, 307,  73,   4,  10,   1,  16,  25, 142, 115, 235,  94,\n",
      "       217, 289, 196, 160, 271, 178, 253, 307,  73,  67, 112,  70, 139,\n",
      "       214, 142, 115, 235,  94, 217, 289, 196, 160, 271, 178, 253, 307,\n",
      "        73,  49,  55,  64, 133, 136, 142, 115, 235,  94, 217, 289, 196,\n",
      "       160, 271, 178, 253, 307,  73,  37,  34,  61,  91,  46, 142, 115,\n",
      "       235,  94, 217, 289, 196, 160, 271, 178, 253, 307,  73,  22,  19,\n",
      "        43,  58,  31, 142, 115, 235,  94, 217, 289, 196, 160, 271, 178,\n",
      "       253, 307,  73,   7,  10,  40,  52,  28, 142, 115, 235,  94, 217,\n",
      "       289, 196, 160, 271, 178, 253, 307,  73,   4,  10,   1,  16,  25,\n",
      "       142, 115, 235,  94, 217, 289, 196, 160, 271, 178, 253, 307])}\n"
     ]
    }
   ],
   "source": [
    "print(result_cvmw.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Multinomial Naive Bayes - Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbc_cv = MNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = Pipeline([('vectorizer', vectorizer), ('clf', mnbc_cv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__analyzer': ['char'],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [0, 5, 10],\n",
    "    'vectorizer__ngram_range': [(2,3), (3,3), (3,4), (3,5), (4,5), (5,5)],\n",
    "    'vectorizer__max_features' : [10000, 15000, 20000, 25000, 30000, None]\n",
    "}\n",
    "\n",
    "result_cvmc = GridSearchCV(model, parameters, cv=10, scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__analyzer': ['char'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__max_features': [10000, 15000, 20000,\n",
       "                                                      25000, 30000, None],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(2, 3), (3, 3), (3, 4),\n",
       "                                                     (3, 5), (4, 5), (5, 5)]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cvmc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.8536897986292399\n"
     ]
    }
   ],
   "source": [
    "print('Best Score : ', result_cvmc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param :  {'vectorizer__analyzer': 'char', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (5, 5)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Param : ', result_cvmc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = result_cvmc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8626673277144273\n",
      "[[1020   95]\n",
      " [ 182  720]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      1115\n",
      "           1       0.88      0.80      0.84       902\n",
      "\n",
      "    accuracy                           0.86      2017\n",
      "   macro avg       0.87      0.86      0.86      2017\n",
      "weighted avg       0.86      0.86      0.86      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('accuracy: ', accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Complement NB - Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_cv = CNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = Pipeline([('vectorizer', vectorizer), ('clf', cnbc_cv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__analyzer': ['word'],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [0, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2), (2,2), (1,3), (2,3), (3,3)],\n",
    "    'vectorizer__max_features' : [10000, 15000, 20000, 25000, 30000, None]\n",
    "}\n",
    "\n",
    "result_cvcw = GridSearchCV(model, parameters, cv=10, scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', ComplementNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__analyzer': ['word'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__max_features': [10000, 15000, 20000,\n",
       "                                                      25000, 30000, None],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2),\n",
       "                                                     (1, 3), (2, 3), (3, 3)]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cvcw.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.9198992377490999\n"
     ]
    }
   ],
   "source": [
    "print('Best Score : ', result_cvcw.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param :  {'vectorizer__analyzer': 'word', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Param : ', result_cvcw.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 0]\n",
      "\n",
      "\n",
      "[[9.99682225e-01 3.17774837e-04]\n",
      " [1.41719144e-01 8.58280856e-01]\n",
      " [2.11745431e-01 7.88254569e-01]\n",
      " ...\n",
      " [2.32183144e-01 7.67816856e-01]\n",
      " [6.55075873e-01 3.44924127e-01]\n",
      " [7.70563868e-01 2.29436132e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred = result_cvcw.predict(X_test)\n",
    "pred_proba = result_cvcw.predict_proba(X_test)\n",
    "\n",
    "print(pred)\n",
    "print('\\n')\n",
    "print(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9335647000495786\n",
      "[[1051   64]\n",
      " [  70  832]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1115\n",
      "           1       0.93      0.92      0.93       902\n",
      "\n",
      "    accuracy                           0.93      2017\n",
      "   macro avg       0.93      0.93      0.93      2017\n",
      "weighted avg       0.93      0.93      0.93      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('accuracy: ', accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Complement NB - Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_cv = CNB()\n",
    "vectorizer = TfidfVectorizer()\n",
    "model = Pipeline([('vectorizer', vectorizer), ('clf', cnbc_cv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__analyzer': ['char'],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [0, 5, 10],\n",
    "    'vectorizer__ngram_range': [(2,3), (3,3), (3,4), (3,5), (4,5), (5,5)],\n",
    "    'vectorizer__max_features' : [10000, 15000, 20000, 25000, 30000, None]\n",
    "}\n",
    "\n",
    "result_cvcc = GridSearchCV(model, parameters, cv=10, scoring='f1_micro',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf', ComplementNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__analyzer': ['char'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__max_features': [10000, 15000, 20000,\n",
       "                                                      25000, 30000, None],\n",
       "                         'vectorizer__min_df': [0, 5, 10],\n",
       "                         'vectorizer__ngram_range': [(2, 3), (3, 3), (3, 4),\n",
       "                                                     (3, 5), (4, 5), (5, 5)]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cvcc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.8543112222150476\n"
     ]
    }
   ],
   "source": [
    "print('Best Score : ', result_cvcc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param :  {'vectorizer__analyzer': 'char', 'vectorizer__max_df': 0.9, 'vectorizer__max_features': None, 'vectorizer__min_df': 0, 'vectorizer__ngram_range': (5, 5)}\n"
     ]
    }
   ],
   "source": [
    "print('Best Param : ', result_cvcc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 0]\n",
      "\n",
      "\n",
      "[[9.99566618e-01 4.33381849e-04]\n",
      " [2.93212371e-01 7.06787629e-01]\n",
      " [2.64703287e-01 7.35296713e-01]\n",
      " ...\n",
      " [1.47189142e-01 8.52810858e-01]\n",
      " [6.65558423e-01 3.34441577e-01]\n",
      " [7.38113039e-01 2.61886961e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred = result_cnc.predict(X_test)\n",
    "pred_proba = result_cnc.predict_proba(X_test)\n",
    "\n",
    "print(pred)\n",
    "print('\\n')\n",
    "print(pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8621715418939019\n",
      "[[975 140]\n",
      " [138 764]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      1115\n",
      "           1       0.85      0.85      0.85       902\n",
      "\n",
      "    accuracy                           0.86      2017\n",
      "   macro avg       0.86      0.86      0.86      2017\n",
      "weighted avg       0.86      0.86      0.86      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('accuracy: ', accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
